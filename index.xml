<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Message Passing</title>
    <link>https://messagepassing.github.io/</link>
    <description>Recent content on Message Passing</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 24 Mar 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://messagepassing.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>いけすかなさの出処</title>
      <link>https://messagepassing.github.io/011-designdocs/06-morrita/</link>
      <pubDate>Wed, 24 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/011-designdocs/06-morrita/</guid>
      <description>Design docs への温度感も、design docs といって想定するものも、けっこう個人差があるのがわかった。
自分は Google がもてはやされていた時代に会社の外からさぞかし良いものに違いないと眺めていた時間が長く、 そのときの印象を拭いきれていないのかもしれない。 会社カルチャーの宣伝を真に受けない大人になったのは、もうちょっとあとなのだった。
ただ design docs への高い期待値はテンプレートにも織り込まれている面がある。 テンプレートを無視すればいいとかずよしさんは言う。じっさい自分は無視しているけれど、 他の人が使う限り冗長で読みにくい design docs が回覧されてきてしまう事実は変わらないんじゃないかな。
Writing Culture むかいさんのいう Chrome の design docs は テンプレート も含め社内のものとは独立して公開されており、これは Chrome 用でサーバサイドからのバイアスとかはない。それに比較的簡素。
一歩さがってみると、チームはそれぞれが必要に応じ自分自身の documentation / writing の (sub)culture をきちんと育てていく必要があって、 そうしないと外側の、自分たちには不似合いな mainstream に飲み込まれてしまう。あるいは文化不在の荒野になってしまう。 自分の不満はそうした不在から来ているのかもしれない。
そして他人が書くものをどうこうしたいと期待するのは不毛だし横柄。 自分はべつに change agent になりたいわけではない。現状は受け入れ、自分が書くものがどうあるべきかに考えを向ける。
説得としての Design Docs かずよしさんやはまじさんのはなしを読んで振り返るに、この手の high-level writing は 具体的なデザインの詳細より問題の分析や説明に労力を割くべきなのだろう。 よくコードのコメントは How ではなく Why を書けとかいうけれど、 それと似ている。自分が書いたものを振り返ると、その点がいまいちだった。
こうした反省を踏まえて最近 push-back されてしまった自分の design docs を時間をかけて書き直し、計画も見直した。 いざミーティング！事前に回覧する時間がなかったので口頭でさっと説明すると、いいんじゃない、みたいなかんじで素通し。 あれ、がんばって書いた渾身の problem analsys とか読んでよ・・・とおもったが、 計画をだいぶ scale down したため人々の警戒が解けたらしい。</description>
    </item>
    
    <item>
      <title>そんないろいろ言うもんかな</title>
      <link>https://messagepassing.github.io/011-designdocs/05-jmuk/</link>
      <pubDate>Sat, 20 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/011-designdocs/05-jmuk/</guid>
      <description>わたしはかずよしさんと近いところがある。design doc、あると便利なときもたくさんあると思っていて、そんないろいろ言うもんかな、という気がする。ただ自分が書くのは苦手。書くのは正直気が重いが、他の誰かがなにかしてるなら「おいおい軽くでいいからdesign doc書いてくれよ」などと思う。うーん身勝手。
実際のところ、自分が書いたものは mini design doc という程度の規模が多いと思う。クライアント側の機能としてそこまで複雑化はしなかったり、テンプレートのなかに意味のない項目がたくさんあったりということはままある。でもalternativesをいろいろ並べてみて検討してみて、自分がそこまで詳しくないエリアの人から「ここは実はこうなんだけど、それだとうまくいかないんじゃない？」みたいなツッコミを受けられることには意味があるように思う。
期待値の高さ もりたさんの文章を改めて読んでみると、design docというものに対する期待値の高さを感じる。そんなにすごいものだったっけ？　いや、そうやって喧伝されてきたことはあったのかもしれないけれど、今どきもうそこまでのものじゃないんじゃないか。書かれたdesign docをあとから参照せよみたいになることってのも、今どきほとんどないんじゃない？　書かれているように、あとでも読むようなドキュメントは別個にいろんな形態で書かれていて、design docはproposalをつくるのに特化していることも多いんじゃないか。つまり、いろんな面ですでに解体は進んでるんじゃないかなぁ。これはそのチームのカルチャーにもよるような気がするけれど。
もりたさんも私も、サーバサイドのしごとをしていないので、いわば「本流」と離れたところにあるので、本流の側ではどうなのかは、じつはわたしもあんまりよくわからないんだけど。
design docのデメリット ありのさんが言うようなデメリットは、自分は正直あんまり感じたことがない。たとえば、design docが大量発生しても、それはそれでべつに大した問題だとは思わない。そういう人が生産的かというとそうでもない気もするが、design docはそれ自体で成果なわけでもないので、そこにだけ血道を上げる人というのは、そこまで多い気がしない。
design docで書いたことと、じっさいにコードとして書いたことが乖離してしまうこと、これはまあ、けっこうある（こないだもちょっとした提案のドキュメントを書いたが、そこに書いたコードスニペットと最終的にコミットされたものはわりと違うものになった）。でも、だからといって意味がないというわけでもない。問題領域を広く共有して、alternativesを検討してみるというのはそれなりに意味のあるプロセスでもあるし、そこから自分の知らなかったような依存関係や考えないといけなかったディティールを教えてもらったり、ということは実際のところそれなりにあるように思う。
けっきょくのところ要は、変更1個でおわるようなものじゃないなら、いきなりコードを送りつけるんじゃなくて何をしたいのか、どういうことを考えてやったことなのか教えてくれ、という話なんではないか。また、数あるアプローチのうちなぜこのアプローチを採用したか自明でないなら、その理由が知りたくもなる。issueでもいいんだけど、issueはそこまで長々といろいろ検討したりする場でもないし。
design docは大規模開発のためのものか いろいろ検討するとか、レビューするとか、コメントをもらうとか、いろいろ自分の書いていたことから考えて見るに、design docというのは大規模開発に特有のなにかなのではないか、という気がする。design docの主要な役割っていうのは、つまるところ「関係者各位と話を通しておく」というようなことでしかない。
ソフトウェアが複雑化するとすべてを把握するのは大変なので、「この機能、こっちのコンポーネントと関係すると思うけどそっちの人にきいてみたら？　なんか地雷あったら教えてくれるよ」であったりとか、「それこっちのコンポーネント使ったらすぐできるよ」であったりとか、そういうことがままある。「この機能を実現するためにこういうRPCを足して、するとこうなる」みたいな構想でいたところ「いやその方針はやめてほしい。こういうのはどう」みたいな提案があったり、というのも実際に見たことがある。もしかしたらミーティングでもいいのかもしれないけれど、毎回いちから話すのはかったるいし大変だし、記録に残さないとすべて忘れてしまうので、なんらかのテキストを書いてそれをシェアして回るみたいなことになる。そういうものとしてdesign docは生まれた。というのはどうか。
はまじさんがkatiを作った体験談はめちゃくちゃおもしろいが、うかいさんとおおむね二人で新しいものを作ったという話なわけで、たしかにこういうものならdesign docも必要ないだろう。ちょっと口頭で話せば済むので。GNU make知っている人とか、android.mkに詳しいAndroidビルドインフラの人であるとかに聞いてみるというのは、もしかしたら意味のあることだったかもしれないけれど、現実的にはそんなに意味のあることだという感じもしない。そういうふうに始まったプロジェクトのように、ことのおこりにはdesign docがない、みたいなことはありがちなのかもしれない。たとえばChromeそれ自体のdesign docなんてものは、まあないだろう、たぶん。でもChromeのしごとをしていて、新しい機能を提案したかったら今なら軽くdocを書いてシェアしてもらったほうがいいことはたぶん多いはず、みたいにして世の中はまわっているような、そんな気もする。
 shinh そう、まあ必要に応じて書いたらいい、くらいのものですよね。なんか過剰に良い文明扱いされている感がある。 OKR とかもそうだけど、便利な時は使うツール、くらいで良い気がしますね。
ところで Chrome の Design Doc 、見たような気がする（そして「グーグルでブラウザ作ってうまくいくわけないやろ」って笑っていた）けど、単に社内 Wiki に Google Browser という感じのページがあっただけかもしれない。
  karino2 必要に応じて書いたらいい、は自分も思う所で、たぶんそこまではここに居る全員の同意が得られそうかしら？
必要になる頻度が「だいたいのケースで必要」と思うか、「だいたいのケースでは要らない」と思うかという所で、仕事の環境や性質とかカルチャーの違いが出てくるのでは無いかな。
  jmuk そうまあ必要に応じてという話で、そこはたしかに誰もが同意できそう。「だいたいのケースで必要」と「だいたいのケースで不要」はどっちも極論な気がしていて、自分としてはその中間ぐらい。あると便利なこともそこそこあるでしょ、というぐらいかな。で、カルチャーとか仕事の性質のほかにも、チームの規模（人数）とかにもよるんだろうなーとは思いますね。</description>
    </item>
    
    <item>
      <title>あまり感情を持ってない</title>
      <link>https://messagepassing.github.io/011-designdocs/04-shinh/</link>
      <pubDate>Sat, 13 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/011-designdocs/04-shinh/</guid>
      <description>僕は Design Doc に対して、あまり感情を持ってない。「Design Doc は最高です！」みたいな話を聞くと鼻白むものもあるけど、有用なケースもあると思う。ただ好悪は置いておいて、めんどくさいから書きたくない。実際のところ、ほぼ書いたことがない。
よりよい未来のため Design Doc は未来の失敗を回避するために有用なのはわかる。特にグーグルのサーバサイドの文化という気がするんだよなあ。グーグルは共有のインフラがすごく多くて、共有のライブラリもものすごく多くて、全てを把握してから開発に入るのは不可能。ひょっとしたら同じものあるかも、と思いつつも Design を書いたら、それは XX でできるよ、ということはありそう。
あと、グーグルの Design Doc のテンプレートには privacy concerns や security concerns という項目があって、こういうのはプロダクトのデザインをひっくり返す可能性がある割に専門家が少なく、前もって相談しておくのは有用だろう。それと最初の方の Background とか Motivation も地味に重要な項目だと思っていて、「それってそもそもやる意味ある？」と実装してからなってしまうのを防ぐ効果もあるように思う。単に自分が解きたいから、解けるから、という理由で存在しない問題に取り組んでしまう人というのが、一定数存在すると思っている。（これはかなりブーメランである）
というわけで、自分より特定領域を知ってる人がいる時に相談する手段としては、まあ割と良いのではないでしょうか。知らんけど……
過去を自分語りする楽しさと、有益さ 設計と言ってもハイレベルから細かいとこまで色々で、ハイレベルなところでは割と有用なんじゃないかな、というのが前段で言いたかったことかもしれない。例えば使うコンポーネント選択とか RPC の流れレベルのハイレベルな決定には有用そうな気がする。 それより細かい話になってくると、 morita さんの「不確実性の軽視」や karino さんの「Design力が過大評価」の話になると思うんだけど、正直実装を書いてるうちにそのレベルの設計はガンガン変わってくるよね、となる気がする。 どうせ実装やってる間に細かい設計はガンガン変わっていくのだから……という意味で、 kzys さんの「デザインの前にプロトタイプ作ります」とかすごく僕は好みの考え方。ホントそれでいいと思うなあ。やってみてわかることってやっぱり多いと思うし。前段で批判した「存在しない問題を解いたけど誰も困ってなかったらから誰も幸せにならなかった」的な状況でさえ、何もしてないよりは成長が得られるだろうし。その様子をハタで見てると「それ事前に相談しておいてくれればもう少し筋の良い提案ができたのに……」となることもあるだろうけど。
グーグルでは一応 Design Doc を現状の design と一致するように更新することが推奨されていた……と思ってたけど、 morita さんがそう言っていないので、あまり自信はない。いずれにせよ多くの Design Doc は実装以降アップデートされてないので、 morita さんの「「古くなってるけどだいたい合ってるよね」という感じで読まれる想定がある」はそのとおりだったと思うし、そこらへんに読むのですらだるくなってしまう理由があるのだと思う。「なんで後で間違ってると判明したかもしれない設計を熱心に読まないとダメなんだ？」ってなりそう。 そんな理由で、細かめの設計は、なんかむしろ事前に書くより後で書くのがよいのかもしれないな、と思った。 morita さんの言及していた ARCHITECTURE.md のように。事前に書くより実際のコードの設計と一致してる可能性が高いので後から参照された時の有用性も高そうだし。僕は割と自分語りが好きというか、ドヤりたい性分なので、そういうのは割と書いたりする。
僕の好みのスタイルと、 kati の例と というわけで、事前段階ではモチベーションの確認、他プロジェクトとの関連性、大枠のデザインに激しく影響する部分だけ必要なら Design Doc なりなんなりで議論して、さっさと実装して、うまくいったら ARCHITECTURE.md を書いてドヤる、というのが僕としては好みなのかな、と思った。ところで、この文章も特に考えをまとめてから書いてないので、この章を書き始めたあたりで、「僕は考えをまとめながら進めるのが好きなのだなあ」と自分の嗜好を自覚した状態。
これを書く前の事前の相談で kati とか Design Doc とかどうしたの？と聞いてもらったのだけど、ちょうどそういう、あまり事前に相談せず後で説明を書くスタイルだった気がするので書いてみる。</description>
    </item>
    
    <item>
      <title>不安とコード</title>
      <link>https://messagepassing.github.io/010-wced/05-morrita/</link>
      <pubDate>Sat, 13 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/010-wced/05-morrita/</guid>
      <description>皆の話を読んで、 自分の「仕事の成果を出すためにいつもコードを書く」論は現実というより願望なのだと気づいた。 仕事で成果を出したいならコードを書く以外にもやるべきことは色々あって、 そういうのはさぼらずやったほうが成果はでる。調査とか説得とか協議とか。ただやりたくない。
同じように「よく考える」みたいな曖昧で前の見えない時間の使い方にも不安を感じ、 コードという tangible な存在に頼ってしまう。 コードを頼りに考えを進められるからコードを書く・・・と言えればかっこいいけれど、 自分は必ずしもそういう類のコードを優先しているとは言えない。
一歩下がると、コードを書かずにいる不安が根にある。
会社員プログラマ、偉くなるとコードを書かなくなるのはよく知られた事実だけれど、 偉くない平社員でもあんまりコードを書かない人はいる。 それでも意味のある貢献はできる。組織がでかいと特に。 自分は厳密には会社員プログラマではなく会社員ソフトウェア・エンジニアで、 広義のソフトウェア・エンジニアリングはプログラミング以外にも割と色々ある。 自分が「雑用」と読んでいる仕事たちの裾野は広い。
一方で、コードを書かないでいるとプログラミングができなくなってしまう、 「雑用」の人になってしまうのではと気が気でない。 だからコードを書いて雑用だけでない自分を確かめたい。 向井さんがいう「マネージャの趣味的なコード書き」に通じるものがある。
以前はまじさんが難しいコードを家で書けばいいと言っていた。 これはコード全般にいえるのかもしれない。 コードを書きたい不満や書いていない不安は仕事の外で晴らしておき、仕事は成果にフォーカスする。
自分は残念ながらそこまでストイックでなく、家ではコードを書くのかわりに ブログを書いたりインターネットしたりしちゃってる。 家でもっとコード書くぞ！・・・と宣言するガッツはないけれど、 今日こうして不安の存在に気づけたのはよかった。</description>
    </item>
    
    <item>
      <title>毎日は書いてないが、言わんとする事は分かる</title>
      <link>https://messagepassing.github.io/010-wced/04-karino2/</link>
      <pubDate>Sat, 13 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/010-wced/04-karino2/</guid>
      <description>WCEDという物自体を今回初めて知ったし、 毎日コードを書く事は意識していなかったし、WCEDしてない。
自分の仕事でのコード書きはどんな感じか オリジナルのWCEDとmorritaさんの話は既に結構違う所なので、 仕事でどうなの？という事だと思うのだけれど、 自分は毎日は書いていないと思う。 そもそも毎日働いてはいないのもあるが（今は60%稼働の契約なので週休4日）、 稼働日も毎日はコードを書いてはいない。
今回の仕事は、大雑把には「今から作るプロダクトが業界でNo.1になるのに必要な機能を作ってくれ、何を作るかは好きに決めてくれ（意訳）」みたいな仕事だ。 何を作るかも自分で勝手に考える（相談はするが）し、割と綺麗に切れている大きめの機能をスクラッチから単独で数ヶ月かけて実装するものが多い。 チームが小さすぎてレビューを頼める相手が居ない事情もあり、 レビュー待ちとかミーティングとかはほぼゼロ。コードを書く以外の仕事は無い。
だいたい2週間くらい何かを調査し、3ヶ月〜半年くらい掛けて実装するみたいなのが多い。 調査期間の2週間くらいはほとんどコードを書いていなくて、 実装期間である三ヶ月〜半年の間はほぼ毎稼働日コードを書いていると思う。
ただ実装期間でもたまに一日以上調査が必要になる事もあって、 完全に毎日という訳では無く、たまに空く日はある。 でもこれはそんなに頻度は多く無いかな。数週間に一回とかのレベル。 これはmorritaさんの言う２つ目のパターンですね。jmukが言っているのも同じ感じに思う。
一日の稼働日のほぼすべてが調査とコーディングだけ。それ以外の時間はほぼ無い。 実際は一日中コード書くのは大変なので、午前中だけの日とか夜だけの日ともある。一週間ではだいたい3稼働日くらいの労働量という形態になっている。
だから毎日書いてはいないけれど、コードを書く量に関しては結構な量書けていて、コードとしてのアウトプットにはまぁまぁ満足している。
コードを書く事、前に一歩進む事 自分はmorritaさんのエントリを見て、Joelの射撃しつつ前進の話を思い出した。
メールとか経費精算とかミーティングとかで、コード書きになかなか取りかかれない。 そんななか毎日ちょっとでも、FogBUGZのカラースキームを改良することだけでも、 とにかくコードを書けていればOKだ・・・という話。
雑用と、パフォーマンス計測とかで時間を溶かすのとは違う気もするけれど、 なんとかコーディングの時間を捻出してそれにしがみつくのが大切な事なのでは？ というのは似た話に感じた。
もともとmorritaさんの言っているバグレポート解析とかコードレビューとか性能問題の分析というのは、 無駄な雑用という訳でも無いし、それ自体コードを書くより価値がある場合もある。 メールとかはだいたい無駄な気もするけれど、これだって必要と思っているから書いているはず。
でも、あとで振り返った時に、そうした活動があまり価値を生んでないように感じる事はあるんだよなぁ。 四半期を振り返って「あれ？これだけしかやってないのはどうなんだ？」というような。 そしてこの感覚はだいたい正しいとも思う。
コードを書くという選択 ソフトウェア開発の仕事でも、なるべくコードを書かないで済ますのが重要な仕事とか、 人の仕事を助けるような形でチーム全体のアウトプットを増やすのが重要な仕事とか、 いろんな形態がある。 コードを書くというのがいつも前に一歩進んでいる事で、それ以外がいつも無駄という訳では無い。
一方でコードを書く事で前進するような仕事はあるし、 「自分の今の仕事はそういう物でありたい」という希望の元に日々頑張ってコードを書く選択をすることもあると思う。 コードを書く事が一歩進む事であるというよりは、コードを書く事が一歩になるような仕事をするという。
自分は今は「コードを書く事が重要な仕事」を選んで受けている。 Individual Contributorとして、自分１人で書くコードでシニアとしての存在価値を示すのを最近の自分のテーマとしている。 仕事を選ぶ段階で「コードを書くという事が前進となっている仕事」を選択している。
結局我々はプログラムが好きなので、そういう選択をするのもまぁ当然ではあるよなぁ。
余談だけど、Individual Contributorって日本語ではなんて言うんですかね？
 morrita 射撃しつつ前進! そうかも。潜在意識で影響受けてそう。ジョエル世代というやつですねえ。
IC は自分は語弊があるのは承知で「平社員」と意訳することが多いかな。 Senior engineer だと「一人前の平社員」でそれより偉いと「できる平社員」。
  karino2 その分類だとたぶん「できる平社員」は結構ラダー高いICですよね。 めちゃくちゃ凄い人なのに言葉から漂うゆるふわ感（笑）</description>
    </item>
    
    <item>
      <title>半分くらいわかる</title>
      <link>https://messagepassing.github.io/011-designdocs/03-kzys/</link>
      <pubDate>Thu, 11 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/011-designdocs/03-kzys/</guid>
      <description>morrita さん、karino2 さんのいう嫌さは半分くらいわかるかなあ。
「Design Doc 書いてください」というのが、設計が終わったあとに実装がはじまる直線的なソフトウェア開発や、設計が難しい/偉くて実装はそうでもないという、上流工程偏重な職業感を想起させるというのはわかる。無駄な Design Doc が書かれがちなのもわかる。文章がないことに文句を言う人は多いけれど、文章があることに文句を言う人は少ない。でもまあ、無駄な実装よりは無駄な Design Doc の方がマシかなあ。
あと、Design Doc を書かなくてはいけないときは、それなりに大手術になってしまう変更を入れるときで、それは初期の設計のダメさであるとか、機能のつけすぎの現れじゃないか、と思うこともある。炎上プロジェクトには、それを消火してくれるヒーローが現れるように、柔軟性のない巨大ソフトウェアには、それを乗り切るための Design Doc が必要なんじゃないか。
一方で、テンプレートが新規のサーバーサイドのシステムを開発するのを想定しているとか、将来に誰かに読まれそうな期待というのはよくわからない。あわないテンプレートは無視すればいいし、昔に書かれた Design Doc を参照するのは自己責任で、書き手がそれを意識する必要はなくない?
Is it that Design Doc? morrita さんのテンプレートの話や、karino2 さんの
 Design Docは形式が広く知られているし、書く時に気をつけるべき事なども良く語られていて、しかも比較的それらの説明は短い。
 あるいは、Design Docs at Google の
 The sweet spot for a larger project seems to be around 10-20ish pages. If you get way beyond that, it might make sense to split up the problem into more manageable sub problems.</description>
    </item>
    
    <item>
      <title>毎日コードを書く理由</title>
      <link>https://messagepassing.github.io/010-wced/03-jmuk/</link>
      <pubDate>Wed, 10 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/010-wced/03-jmuk/</guid>
      <description>わたしはコードはわりと毎日書いている気がする……仕事では（趣味ではとても毎日は続かない）。といってもべつにgithubを使っているわけじゃないから草が生えるわけでもないし、そういう可視化を励みにしているというわけでもない（むかし、Chromiumコードベース全体のコミット数ランキングの社内ダッシュボードみたいのがあったことがあり、そこではそこそこ上位になっていて嬉しかったということはある）。ただ、どっちかというと自分の趣味嗜好のようなものとして、結果的にそうなっているという方が近い気がする。
もちろんコードを書く＝コミットをマージするというわけでもない（コードレビューなどのプロセスもるから）し、実際には本当に文字通り毎日というわけでもないだろう。ずーっとデバッグだけして何も成果がないときもあるし。でも実際に自分のコードレビュー履歴 を見てみると、まあまあそれなりにちょこちょこ書いていることが多い気がする。
ただ、仕事においてWCEDがいいかというと、現実的になって振り返るとデメリットのほうが大きいとは思う。細かい雑用みたいな小さな仕事に手を付けがちで、大きな問題を放置してしまいがちになってしまう。もりたさんの書くような、雑用がみるみるうちに片付いてやることがなくなってしまった、なんていうのはある意味成功事例かな、という気がする。無限に雑用が湧いてくるようなタイプのプロジェクトの場合、いつまでたっても細かい雑用しかせず、結果的に大した成果もないし出世もしない、みたいな話になりがちなのがいちばん危なくて、バランスを取る必要がある。
もちろんプロジェクトのフェーズによっては、難しい問題について考えたり、考えをドキュメントにまとめたり、他人のドキュメントやコードをレビューすることで忙しくなってしまう、ということはある。それでも自分の場合は、他人にレビューコメントを送って返事がくるまでの間に細かいバグを直したり、みたいにしてコードを書く時間を設けていることが多いかなと思う。そのままバグの分析に熱中してしまってメインの大きな仕事がおろそかになってしまうことも、まああるのだけど……。
やっぱり個人的にはWCEDは自分の精神の安定性とか、満足度とか、楽しさとかのためにあるように思っている。小さな成果が積み重なっていく感じがあって満足度も高いし、ちょっとした達成感もある。ただやりたいのでやっているというぐらい。いってみれば趣味というようなものなので、そちらに行きすぎないようにうまくバランスをとらないといけないのだろう。あんまり自分がバランス取れている気もしないので、そこは大きな問題な気もする。
少し話はそれるけど、10年ほど前の上司の上司がdirectorに昇進したとき（directorっていうのは日本語だとなんなんだろう、部長、ぐらい？）、俺はdirectorになるけどコードは書くぜ！といった意気込みを示したことがあった。それからしばらくしたある日、私がちょっと遅い時間に仕事をしているとそのdirectorが私の席までやってきて、真剣な顔でちょっといいか、ききたいことがあるんだが……と言う。これはやばい話かもしれない、と戦々恐々としつつdirectorの席までついていくと、画面にeclipseが開いてあって「この関数をテストしたいんだけどさ……」というのであった（その部分は自分は詳しくなかったのであんまりきちんと答えられなかった。残念）。このdirectorは、その後更に出世したしさすがに今ではコードは書く時間もないだろうけれど、当時でもめちゃくちゃ忙しかったであろう合間をぬってでも細かい雑用みたいなコード書いていたのだった。これは偉いというかすごいと思った。が、今思えばあれはなんというか、この話と似たような趣味的な活動だったのかもしれない。every dayでないにせよ、定期的にコードを書いていたいというような。まあそれでいてその人は出世できてるんだからやっぱりすごい偉いという話でもあるんだが。
 shinh それた話題に喰いつきますが、マネージャーが全力でコード書いてるのはアンチパターンな気がするけど、十分に偉いリーダーがコード書いてると心を鷲掴みにされるもんがありますよね。実際 report のやってることを解像度良く把握するのに有効な気もするし……   </description>
    </item>
    
    <item>
      <title>曖昧な立場</title>
      <link>https://messagepassing.github.io/011-designdocs/02-karino2/</link>
      <pubDate>Fri, 05 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/011-designdocs/02-karino2/</guid>
      <description>Design Doc、自分は無駄なケースが多いと思っているけれど、書いて欲しい場合もある、 という曖昧な立場で、読んでもスッキリしない感じになるかもしれないが、 そういう立場の人も多いと思うので書いてみる。
コミュニケーションの手段としてのDesign Docの有用性は高い（事がある） 設計について相手が考えている事を知りたい時に、Design Docを見せて欲しいと思う事がある。
特にこれから作ろうとしている物に明らかに幾つかの選択肢があって、 それぞれ長所短所があってどれが最善か良くわからない時、 相手が選んだ選択の理由を知りたい。（当然その選択が自分に関係ある場合。）
プロジェクトにはいろいろな背景事情があって、 その結果そのデザインが選ばれたと思う。 でも背景とかの事情には必要な事以外あまり興味が無く関係ある事だけ知りたい時、 Design Docとそのレビュー結果を見たい。
技術的にどちらが良いのかわからない重要な選択のうち、 なぜ一方を選んだのか、その意思決定には多くの情報が含まれる。 それを読む事で背後にあるいろいろな関連する事情も想像出来るようになる。 そこから芋づる式に必要な事を追加で質問していくのは、 最初から重要な所だけにフォーカス出来て効率が良い。
またあまり背景知識が無い状態では、何の準備も無く顔をあわせて説明を受けたり質問をしたりするよりも、 片方が考えている事を一通り書いてもらい、それを読んでから顔をあわせて質問したりする方がコミュニケーションの質が良い。 そういう時に何を書いて欲しいかを示す時、良く知られているDesign Docの形式は便利だ。 トレードオフや代替案などにフォーカスするスタイルは、良い切り口である事は多い。
その結果として残る物にもそこそこ価値があるので、 無駄なミーティングをへらす為のコミュニケーション手段としてもDesign Docはなかなか良いと思う事がある。
設計について話し合うテンプレートとしてのDesign Docのスタイル 設計について考えて話し合いたいとき、とりあえずコードを書いてきただけの経験の浅い若手などは何を話していいかわからない事がある。 特に入社からずっと１人チームとかで他のチームのベテランと話した事とか無いんですが・・・・みたいな人。 ちょっとこれから作るものはベテランの意見をちゃんと取り入れて欲しい、みたいなときに困る。
そういう時に「設計について考える」ことに期待される内容を伝える際、 Design Docを書いてレビューをしてもらう形式は提示しやすい。 それを元に議論してもらえば自然とやって欲しい事をやってもらえて、 そのやり方にはそれなりに有効性もある気がしている。
Design Docは形式が広く知られているし、書く時に気をつけるべき事なども良く語られていて、しかも比較的それらの説明は短い。自習もしやすい。 だから企業文化の違う相手にとりあえずやってくれと要求しやすい。 また相手がベテランなら、好き嫌いはおいといてだいたいは慣れ親しんでいるので、 何をして欲しいのかを簡単に伝えられる。
自分もそういう形式に慣れているおかげで、 Design Docとレビューのフィードバックを見れば、 どういう話し合いをしたかがだいたい後から分かる。 もっと言うと、どういう話し合いを「していないのか」も分かり、こちらの情報が重要な事も多い。 漫然とした打ち合わせと結論のよくわからないふにゃふにゃした議事録よりは、 Design Docとレビューを中心とした議論の方が周りからも分かりやすい。
無駄なDesign Docが大量に書かれがち そんな訳で有用なことはあると思っていて、書いてほしいと依頼する事もあるのだけれど、一方で好きになれない事も多い。 一番好きになれない所は、明らかに誰も読まないようなDesign Docが大量に量産されがちな所。
morrita氏が最初にリンクを貼ったDesign Docs at Googleでは「Design Docを書くべきでは無い時」という話が書かれているが、こういう時にもいかにも書かれがちに思う。 また、上記ではdesign problemに曖昧性があれば書くのが有効に読めるけれど、そういう場合でも有効でない事はあると思う（後述）。
Desig Docが有効で無いそういう状況でも、 Design Docを書いてレビューをもらうスタイルが浸透すると、Design Docを書いてしまいがちだ。 有効で無いDesign Docは負担が多く利益が少ない。</description>
    </item>
    
    <item>
      <title>Design Docs のいけすかなさ</title>
      <link>https://messagepassing.github.io/011-designdocs/01-morrita/</link>
      <pubDate>Thu, 04 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/011-designdocs/01-morrita/</guid>
      <description>Design docs というのが昔からあまり好きでない。読むのも書くのも好きでない。 仕事で文書を書くのはやぶさかではないけど Design docs はなんとなくいや。 せっかくなのでこのイヤさを言語化してみたい。
Design Docs とはなにか 自分が想定している Design docs は この文章が説明しているようなものだ。 なにかそれなりの規模があるものを作る時に設計やそのトレードオフをざっと文書化する文書。 もっというと一般名詞の design docs ではなく、リンク先に書いてあるような自分の勤務先固有の The Design Docs 文化が好きでない。
「設計やそのトレードオフをざっと文書化する。」 それだけ聞くと割と良いもののような気がして、自分もある時期までは良いものだと思っていた。 「ドキュメンテーション」というのは、プログラミングのポップカルチャーにおいては伝統的に嫌われものである。 そんななか Design docs は旧来のドキュメンテーションが持つ官僚的、形式的なイメージを覆し、 必要最低限の情報をインフォーマルに伝える手段として新風を吹き込んだ・・・気がしていた。十年以上前、具体的な実装を見るまでは。
しかし実際に仕事で Design docs を読んだり書いたりしてみると色々と欠点も見えてくる。
欠点 1: 想定されている問題領域の狭さ Design docs は、ある規模のものを「新規に」開発する暗の想定がある。 ついでにそこで想定されているのはサーバサイドのシステムみたいなやつである。 社内に用意されているテンプレートはこうした想定を強く織り込んでいる。 けれどモバイルアプリのコードをリファクタリングをしたり UI を増改築したり性能改善をしたり奇妙なバグを直したりに 大半の時間を費やしているしている自分にとって、この想定は他人事。
先にリンクした文書では、インクリメンタルで比較的規模の小さい仕事には “mini design doc” を書くと良いといってるけど、 その書き方については特に論じず、簡潔にしとけよ、オーバーヘッドでかいだろ、とかいうだけ。この無関心さが暗黙の想定を裏付けている。 実際、あたらしいシステムをバンバン設計なさっている立派な皆様ほど Design docs を好まれる。
欠点 2: 期待されている守備範囲の広さ Design docs の主目的はなにか大きなものをつくる前に重要な意思決定 (アーキテクチャといってもよい) をレビューすることである。 つまりレビューが済んだら基本的には用済みだ。にも関わらず、 Design docs は部外者や新参者が既存のソフトウェアのデザインを読み解くための文書としても使われている。 「古くなってるけどだいたい合ってるよね」という感じで読まれる想定がある。</description>
    </item>
    
    <item>
      <title>毎日を細切れにされるのはきつい</title>
      <link>https://messagepassing.github.io/010-wced/02-kzys/</link>
      <pubDate>Wed, 03 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/010-wced/02-kzys/</guid>
      <description>仕事に WCED は無理があったのか、それとも自分の仕事の仕方がよくないのか。 みんな仕事で毎日コードかいてんの？どうなの？
 Write Code Every Day してないなあ。毎週はなにか書いていると思うけれど、毎日といわれると怪しい。
仕事の外での Write Code Every Day は How the GitHub contribution graph is harmful (2016) という話があって、実際に GitHub からも連続日数表示が消えてからはや5年たつ2021年に目指すものではないと思うけれど、仕事でも毎営業日コードを書いてはいない。
理由は morrita さんと大体同じで、人にブロックされることとか、難しめの仕事とか。さらにいうと、後者には大抵「設計を文章にまとめて人々に相談してみる」すなわちミーティングの主催も含まれがちで、そうするとミーティングの日まで人にブロックされることになる。
毎日コードを書けないのはいいけど・・・ というわけで、毎日コードを書けないのは、個人的には許容している。コードを書く前に立ち止まって考えたほうがいいことは、立ち止まって考えたらいいじゃない。一方で、毎日をミーティングで埋められて、かつその合間が30分とか1時間なのはつらい。
そういうのが散見されるときは、自分のカレンダーを自分の予定で事前に埋めるというのを実践していて、適当な時間に2時間程度の長さの予定を入れている。ミーティングを入れるソフトウェアは一般にダブルブッキングを避けてくれるものなので、ここで難しい仕事とか、やらないといけない仕事にちょっと進捗を出す。2時間程度の連続した時間がとれない日には、人々の仕事をがんばって手伝ったということにして、自分の仕事が進まなくてもあまり気にしない。
メールは夕方4時まで読みません、というのは会社員にはちょっと厳しいと思うけれど、オフィスにちょっと早めに来て、仕事の最初の1時間くらいはメールを読まない、というのは一時期やっていた。最近やっていないのは、なんでだっけ? また再開してもよさそう。メールも Slack も、他人の TODO が高速に飛んでくるメディアという側面があるので、あんまり貼り付いているのは良くない。
毎日コードが書けないのが許容できて、ミーティングで時間を細切れにされるのを許容できないのは、多分自分の仕事の多くは「考えること」で、難しいことを1時間程度で考えることはできないと思っているからだと思う。訓練を積んだら出来るようになるのかもしれないけど、あまりに大企業最適化すぎるので出来るようになりたいかというと微妙な気持ち。</description>
    </item>
    
    <item>
      <title>Write Code Every Day At Work</title>
      <link>https://messagepassing.github.io/010-wced/01-morrita/</link>
      <pubDate>Tue, 02 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/010-wced/01-morrita/</guid>
      <description>去年一年の仕事を振り返っていて、いまいちコードを書いていないことに気づいてしまった。
プログラマの下っ端がコードを書かずに何をしているかというと、 バグのたらい回し、バグレポートの解析、コードレビュー、メールとか報告とかの自然言語書き、バグのたらい回しとか。 下っ端には下っ端の雑用があり、特に性能問題の分析は無限に時間を溶かしがち。去年はだいぶ溶かしてしまった。
その反省からもうちょっとコードを書こうと、去年のおわりくらいから午前中は雑用をすべてすっぽかしコードを書くことにしてみた。 いわゆる Write Code Every Day (WCED)。
やってみると腰が重くて放置していた積み残しの仕事たちがあれよあれよと片付き、コードも書けて満足度も高く、 なぜこれをやっていなかったのか（答: 色々な圧力があったから）不思議なくらい捗った。のだけれど、ここ一週間くらい行き詰まってきた。 というのも、即座にコードの書ける仕事が手元からなくなってしまった。
１つ目のパターンは、誰かを待つ必要がある仕事。わかりやすいのだとコードレビューとか。 あとは人のコードベースに踏み込んでなんかやるために方針を相談するとか。 話がつくまでそのあとの作業ができない。 まあこれは自分にとって付き合いの長い問題なので、並列化とかでそれなりに乗り切れる。
２つ目のパターンは、真面目に考えないといけないむずかし目の仕事。 うーんと考える。既存のコードやインフラのドキュメントを読む。方針とかを書き出して関係者の反応を見る・・・など、 コードを書くためのコード以外の準備がそれなりに必要なもの。
個人的にはこの２つ目に手強さを感じている。 自分は考え事や調査に時間を溶かしがち。しかも考え事をするとコードを書く勢いが止まってしまう不安がある。 気がつくとまた雑用の引力に引き込まれてしまうんじゃないか。
そんな気の重さに負け、つい優先度の低い細かいリファクタリングやバグ修正を優先してしまったりする。 でもそういうことをしていると大事な問題が前に進まない。
世の中の WCED 体験談にも、似たような意見を見かけることがある。 WCED はもともと課外活動のためのアイデアなので、それなら WCED を目的にして手段を調整すればいいといえばいい。 課外活動の WCED はそうやって問題を回避している。たとえば coding quiz や教材を優先する、みたいな。 でも自分は仕事をはかどらせるのが目的なので、同じ方法は使えない。
仕事に WCED は無理があったのか、それとも自分の仕事の仕方がよくないのか。 みんな仕事で毎日コードかいてんの？どうなの？</description>
    </item>
    
    <item>
      <title>Re^3: 読むものさがし</title>
      <link>https://messagepassing.github.io/009-feed/04-karino2/</link>
      <pubDate>Sat, 20 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/009-feed/04-karino2/</guid>
      <description>皆の話を見て、自分はどうしているかなぁ、と今BooxのInstapaperとPocketを眺めてみたのだが、なかなか雑多な経路から入っていて端的に言うのがなんか難しい。 とりあえず個別に話してから雑感的な事を述べてみよう。
RSS関連 RSSは長らく既読にするだけという感じだったのだけれど、Booxを買ってから最近また活用するようになった。
7割くらいは読まずにarchiveになっていて、無駄だなぁ、とは思っている。一時的にオフに出来たらいいかもなぁ。 ちょっとオフトピだが、天文とか経済学とかが、最近は読まずにarchiveする比率が高い。 こういうのを読む気分じゃないのは一時的な物なので、アンフォローしたい訳でも無いのですよねぇ。 仕事やめて星を見る機会が増えたらまた見たいのだけれど。
RSSリーダーはInoreader使ってます。
読み方としてはざっとRSSリーダー上で確認して、気になったのはInstapaperに送る。以前はPocketに送ってたが、最近Instapaperに乗り換えを検討してて評価中。 後述するけれど、長いものは意図的に読む比率を上げています。 Instapaperに長いのを送るようになってからRSSを読む楽しさが増した気がするのでBooxは偉大だ。 なお今見直したら、送った奴はだいたい読んでいる模様。ちょっと意外。
友人知人と企業とかの区別は特に無く適当に加えてます。 昔はフォルダ分けとかしてたが最近はしてないので形骸化したフォルダが残ってて不便。
subscribeしている中で、割と良く読むブログを、読む率の高さ順で紹介しておく。
 Official Kotlin Blog  Kotlinの話は結構読んでいる気がする。事例紹介とかは飛ばす事も多いが、ここからリンクをたどって気になったのを読むケースも結構多い。これが一番真面目に読んでいるかな。
 Android Developers Blog  これも結構読んでいる。
 The Old New Thing  Microsoftの人のC++とかWindows関連のブログ。 最初はC++関連でググってたどり着いたが、Windowsの話とかもたまに見ている。読まないで飛ばす率も高い。C++の話の時は結構読んでる。
 2ality – JavaScript and more  以前Exploring ES6という本を読んで、なかなか良かったので、その後著者であるこのサイトをsubscribeしている。 JS関連はそこまで興味ある訳でも無いので飛ばす事も多いが、眺めるくらいはしているかなぁ。
 Google Developers Blog  TensorFlowとか興味がある奴だけ読んでる。これも飛ばす率は高い。
あと、kzysブログとshinhブログからリンクされている技術系の記事は結構読んでる気がする。
その他統計とか機械学習系はsubscribeしているが最近は全然読んでない。そっちの界隈に復帰したらまた読みはじめるかも。
TwitterとかMessage Passingとか RSS以外だと、Twitterで流れてきたのをInstapaperに送ってるのと、Message Passingでkzysとかが紹介しているのをInstapaperに送ったりとかはしている。 SNSは技術系の流入はだいたいTwitterからかなぁ。 自分の中ではTwitterからの流入とMessage Passingからの流入は割と同じカテゴリに入っている気がする。
自分は結構SNSやってる方だとは思うが、バズってる話題とかには極力近づかないようにしていて、そういうリンクは意識的に踏まないように心がけている。見てしまうと反応したくなるので。 だからSNSでつぶやいている量から想像されるよりは、Twitterからの流入は多くない。流入としてはRSSの1/3以下くらいかなぁ。
Message Passingからの流入の方がSNSからよりは気もち多い気もする。
ググった物 Instapaperを見ていて思うのは、単発の技術記事の多さ。どこから入ってきたかなぁ、と思うと、ググって見た物と、そこからリンクされてた物、みたいなのが多い。
例えばThe Rise of ``Worse is Better&#39;&#39;とか、Basics of the Unix Philosophyとか、LWN.</description>
    </item>
    
    <item>
      <title>Re: Re: 読むものさがし</title>
      <link>https://messagepassing.github.io/009-feed/03-kzys/</link>
      <pubDate>Wed, 17 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/009-feed/03-kzys/</guid>
      <description>自分は morrita さんと jmuk さんの間だと、morrita さんよりかなあ。ソーシャル少なめ。RSS 多め。
読みはじめたもの: ニュースレター 近頃流行りのニュースレター。私は Cindy Sridharan さんがニュースレターをはじめるというので、彼女のものを皮切りにいくつか購読している。いまのところ楽しみに読んでいるのは、Nelson Elhage の Musing in Computer Systems と、Hillel Wayne の Computer Things。
Nelson Elhage さんは、以前もふれた Sorbet の初期開発者の一人であり、Accidentally Quadratic の編者でもあった人。「コードレビューについて」みたいな平和なものから「Clang がこれを最適化しないのは変だと思ったんだけど、Alive2 っていう形式手法を使ったやつがあってさあ」みたいなマニアすぎるものまで話題が幅広く面白い。
Hillel Wayne さんは、こちらも以前にふれた &amp;ldquo;Practical TLA+&amp;rdquo; の著者の人。この人はブログもちゃんと更新されていて、その紹介の日もあれば、ニュースレター専用のエッセイもある。
形式手法の人だと思っていたら、ブログでは「ソフトウェアエンジニアはエンジニアと呼べるのか?」というたまに見かける話題に対して、実際に他分野のエンジニアにインタビューしたりしていて、なかなか手広い。
ずっと読んでいるもの: ブログ ブログは Feedly で読んでいる。livedoor Reader 時代は多読傾向があったのだけど、最近は控えめ (50前後)。セコンさんとか、Julia Evans さんとか、インターネットスターを追いがちで、いま見返すと仕事に直接関係あるものは少ない。
読まないつもりのもの: ニュース ニュースは、Hacker News, Lobsters, はてなブックマークあたりを見ていたんだけど、2021年はニュース消費を減らすつもりでいて、LeechBlock で土曜日以外はアクセスできないようにしている。
Cal Newport の &amp;ldquo;Digital Minimalsim&amp;rdquo; (邦訳『デジタル・ミニマリスト』) の影響、と言いたいところだけど、ニュースを読まないという話は、どちらかというと &amp;ldquo;Make Time&amp;rdquo; (邦訳『時間術大全』) の影響かもしれない。著者の一人である John Zeratsky の Why I Ignore the Daily News は、要するに「毎日ニュース読まなくていいでしょ。かわりに、毎週 The Economist 読んでるよ。」という話で、まあ私は The Economist も読んでいないんだけど&amp;hellip;</description>
    </item>
    
    <item>
      <title>Re: 読むものさがし</title>
      <link>https://messagepassing.github.io/009-feed/02-jmuk/</link>
      <pubDate>Tue, 16 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/009-feed/02-jmuk/</guid>
      <description>うーん、そんなにいろいろ読んでいるかなぁ。
RSSフィードは私も情報収集にはあんまり使っていない。Feedlyを無料枠で使っているけど、使い方はけっこう雑。一日一回眺めるぐらいで、フォローしているのもたいがい知り合いか、そうでなくても比較的生活感の強いブログが多い。技術系の記事はフィードに入れてるやつもあるんだけど、雰囲気がミスマッチしているからか、あんまり読めていない気がする。
ほかでもたとえば、Hacker Newsも、トップページを眺めることはあんまり多くない。Redditもあんまり見てない。ニュースレターも、そこそこ登録はしてたりするんだが、あんまり読めてない。どうもこういうものを読むことが生活サイクルに組み込めてない感じがある。あと仕事内容とか興味のある技術分野とマッチしたニュースレターをあんまり見つけられていない感もあるかな……。この辺はもう少し掘り返してみたほうがいいような気もする。
というぐあいに「残念」なかんじなのにいろいろ見てるような印象を与えられているとしたら、たぶんソーシャルなサービスのおかげかなと思う。
たとえば、技術系記事の情報源は Twitter に頼っているところが大きい気がする。知り合い、同僚、同業有名人、技術系のニュースメディア（The Vergeとか）、そういった人々を適当にフォローしていて、彼らの紹介するリンクを消費している。そういえば、Twitterは昔ながらの時系列順のタイムラインと、Twitterが関連性の高いものを勝手に流してくるレコメンデーションベースのタイムラインがあるが、わたしは古参には不評な後者を使ってる。これのおかげで直接的にはフォローしていないような記事もタイムラインに上がってきていい面もある。ノイズがめちゃくちゃあるのと時系列が完全に破壊されるのが欠点だが、適当に流し見する目的ならこのほうがよいというふうに納得している。
あとは Hacker News 100 という、Hacker Newsで100以上のupvoteを集めた記事だけを流すbotアカウントがあって、これもフォローしている。100以外にもいろいろあるみたいだけど、HNの記事はこういう、何らかの基準でフィルタされたやつだけでいいかな、という気持ちがある。
あとはてブ。はてブはブックマークコメントは見るとウッとなるが、紹介されてる記事には面白いものもそれなりにあるので、そこから興味をもった記事を読んだりしている。コメントは見ないよう心がけている。あと過度にブクマを集めすぎている奴は炎上なだけなので、もっと穏当なやつのほうがおもしろい。
最後にGoogleの、えーと今なんていう名前なのか知らないんだけど、おすすめの記事を勝手に教えてくれる機能がある。あそこからいろいろ記事を読んだりもしている。ただ技術系の記事については正直なところぜんぜんかな。ローカルニュースとか、映画とかのネタは妙に豊富に拾ってくれて、まあまあ便利に使っています。とはいえ、玉石混交できびしい面もあるけれど。
まとまりがなくなってしまったが、しいていうなら、自分でフィードを整備するのではなくて、大企業のAIの力を利用してその流れに乗っている、といえるかもしれない。とか言ってみたらかっこいいかなと思ったけど、そうでもないな……。
 morrita Twitter, 人々がやってるのにはわけがあるとわかる話ですね。すっかり忘れてしまってるけれど、使ってみると良いところもあるのだろうな。
Google のあれは今でも Discover でいいんじゃないかな。 自分は Chrome でも Google Search App でも無効にしてます。案の定といえよう。
  </description>
    </item>
    
    <item>
      <title>ちゃんとやりすぎた Chainer</title>
      <link>https://messagepassing.github.io/008-justright/05-shinh/</link>
      <pubDate>Thu, 28 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/008-justright/05-shinh/</guid>
      <description>Worse is better といえば、 Chainer ってちゃんとやりすぎていたのでは、て話をよくするんですよね。まあうまくさぼってたら競争に勝ち残れてたかというと別の話なんですけど。 Chainer の開発終了する時の PyTorch への移行ドキュメントとか、 PyTorch の人が感心してたりしたけど、ホント丁寧だなあと感心する。
一方で、 TensorFlow はともかく、 PyTorch はかなりわちゃわちゃしてて、こんなんでいいんだ……とよくなる。例えば、「LogSoftmax て exp に渡すの負にしないとすぐふっとぶから定義通りではダメで、なんかするけど、なにするんだっけ……」みたいなこと調べる時に、 PyTorch のリポジトリの下で git grep して、「さっぱりわからんな……」となってから Chainer 見てすぐわかる、みたいなことがよく起きる。ちなみに log(sum(exp(x))) を max(x) + log(sum(exp(x - max(x)))) で計算すると良いという話。
あのカオティックな状態で人気ナンバーワンというのは、さすが Done is better than perfect の総本山、と感心するものがある。なんかでもかくいう Chainer も高速な CPU 実行は numpy に丸投げ、 cupy の実装は大変とはいえ少なくともインターフェイスは numpy のものを使えば良い、など、割といい感じに手を抜けるちょうどよさを持っていたという側面もあるかもなあ、と。ちゃんとやらなさすぎても見捨てられるので、いい感じのバランスを取るのはかなり難しい、という話かもしれない。
 morrita 一方 TensorFlow は Move fast and break things しすぎて人々に見放されてしまったのだった・・・。はさておき NumPy の API は「ちょうどいい」一族に数えて良い気がする。   shinh TensorFlow に限らずグーグルは、ちゃんとやりすぎててもなんとかなるどころか人が余りまくって仕事を奪いあうくらいのリソースがあるから回ってる感がありますよね。まあ流行るかというと、あのいつもの社内のもの出しただけグーグル OSS 感ではなあ……というような話は別トピックですると良いですかね。</description>
    </item>
    
    <item>
      <title>Go言語のちょうどよさ</title>
      <link>https://messagepassing.github.io/008-justright/04-jmuk/</link>
      <pubDate>Wed, 27 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/008-justright/04-jmuk/</guid>
      <description>Go言語は、なんというか「ちょうどいい」言語だな、と思っている。異論は認める。
Go言語の登場時、なんせGoogleが大々的に発表した新しいプログラミング言語であるし、Rob PikeやKen Thompsonといった有名人の関わりもあり、華々しかった。そして、その登場を眺めたプログラミング言語マニアは、そのダサい仕様にわりとすぐがっかりして、興味をなくした。ということがあったと思う。今はGoはけっこう広く使われていて人気もあるけど、ここに至るまでには紆余曲折があった。
Go言語、なにせ2010年代にもなってなんせジェネリクスもない（そのわりにスライスや配列、ハッシュテーブルだけが標準にあり、特別扱いされている）。例外処理もない（これはまぁそのほうがいいだろうという人もいるだろうけど）。そこらじゅう if err != nil だらけ。テストにアサーションもなく、ひたすら地道にif文を書くべしとされている。いくつかのビルトインな関数（たとえば makeなど）は構文上も特別扱いされていて、直交性がかけらもない。
オブジェクト指向的なことはできるが、C++やJavaのようなクラス志向ではない。継承が言語仕様にない。interfaceによるduck typingはできる。メタプログラミング的なことはやりづらい。オブジェクトは動的なところが一切ない。なんかデザインしづらそうだな、というふうに思った。
というわけで、登場時は「なんだかぱっとしない」「かっこよさがない」といったイメージであったように思う。すくなくとも自分は。
Go言語の「ちょうどよさ」 結果的にはこういうマニア視点はまったくのお門違いだったといえるだろう。Go言語はおおいに流行っている。これをGoogleによるゴリ押しだという主張はきっとあるだろうけれど、それはたぶん違う……もちろん、会社の支援のもとで言語仕様の改善や標準ライブラリの拡充などの発展があって便利になっていったという側面はあるけど、それはまあ「ゴリ押し」とは言わないだろう。
Goの独特のニッチにうまくハマったのだと思う。それはたとえばWebサーバやRPCサーバ、ちょっとしたユーティリティツールやサービスにあたる。GCがあって、並列処理ができ、標準ライブラリだけでもけっこういろんなことができて（http2サーバでJSONを返したりとが簡単にかける）、単純だけど静的型付けで単純な間違いは防げる。Goのインタフェース志向なduck typingは使ってみるとわかりやすく簡単だったし、実装の継承があると便利な場面というのも別になかった。こういう用途には便利だった。
言語マニアが「ださい」と思ったところは、実用上はそんなに大きな問題になることが多くはなかった。多くのGoプログラマが証言するように、Goを書いていてジェネリクスが必要なのになくて困るという場面はほんとうに少ない。もちろんまったくゼロではないし、今後たぶんジェネリクス的な機能は入ることになるだろうから、それはそれでいいことなんだけど、でも、マニアの文句なんてそんなもんだという話でもある。標準組み込み型の特別扱いがわりとうまく機能してるとも言える。
Goコマンドの導入によりツールチェインはわかりやすく使いやすくなったし、ビルドも速く、シングルバイナリでデプロイや配布が単純というのもよかった。こういうところは言語マニアはあんまり評価対象としないと思うけれど（言語そのものというよりは処理系の話だし）、そこには大きな意味があったと思う。Goは性能がよいというイメージ（実際のところ、最速でないにしろスクリプト言語よりは十分速い）も普及に一役買ったことだろう。
Goはworse is betterか？ Goの「ちょうどよさ」というのはどういうものだろうか。先進的でかっこいい理論にもとづいた複雑な言語より、ダサいけど使いやすいのがいい、というのが端的な評価になるとおもう。これはworse is betterを思わせるところがある。ただ、読み直してみると、Goはworse is betterでいうところのNew Jerseyアプローチではないように思える。
Worse is betterの結論というのはこうだ。実装が簡単で使うのも苦じゃないようなものは、みんなが勝手に再実装しやすい。そういう再実装は完璧じゃないにしてもまあまあ使えて同じぐらい使いやすい。そうやってウィルスのように広がっていく。MITアプローチで作られるものは、ぜんぜん完成しないか、完成しても使い物にならないかで流行らない。
JSONはまさにworse is betterといえる。自作JSONパーサを作るのだってすごく大変じゃない（性能とかを気にしなければ）。コンパクトでミニマルである良さみたいなものがある。
でもGoはランタイムも大きくてけっこういろんなことをしてくれる言語だ。GCもある。goroutineはカーネルスレッドの複雑さを隠蔽してくれる。再実装はぜんぜん簡単じゃない（実際、Goの再実装なんてllvm-goとか数えるほどしかない）。GoはいろんなOS、アーキテクチャに移植されてるけど、これはどっちかというとエンジニアリングリソースの投入量によるところが大きそうだ。それにまた、Goは裏側で意外といろいろ複雑なことをしてくれることがある。Goは間口の広さと取っ付きの良さ、仕様のわかりやすさによって普及したが、そのわかりやすさ、単純さのためには実装の複雑さを引き受けている面がある。かといってMITアプローチともいいがたい。
これはたとえばTOMLのちょうどよさにも通じるところがあると思う。TOMLは書き手にはシンプルでいい言語なのだが、これまたnew jerseyスタイルではない。実際に再実装するのは意外と厄介。仕様は細かいところまでいろいろカバーされており、こういう場合はエラーになる、こういう場合はこうなる、といった仕様をすべて正しく実装するのはじゃっかん面倒くさい。そういうこまかい部分がありつつも、全体的には「なんとなく人間が書いてわかりやすいような挙動」が取られるようになっている。データ型も日付型とかがあったりしてミニマルな良さもない。
まあいまさらworse is betterでもないだろうという話でもないのかもしれない。あるいは、MITとNew Jerseyの相克は、「ちょうどよさ」の新しい相を生み出したのかもしれない。これが今の時代のちょうどいい表現なのかもね。言い過ぎな気もするけれど。
 karino2 Worse is betterはそのまま現在に語るにはどうなのか、とも思う反面、現在のコンテキストでうまい感じに翻訳して語れんもんかなぁ、という気もしている。 YAGNIとかworse is betterとかってきっちりした主張ほどわかりやすく無いのだけど、割と重要なものを含んでいる気がするのだよなぁ。
自分のGo言語評価を聞きなおしたら、 worse is betterとは言ってないが似たような事を言っている気がした。
ちょうど良さというか、だいたいこんなもんでいいんだよ感というか。
  kzys Manning から出ている Functional Programming in Scala の著者の一人でもある Paul Chiusano が、The problematic culture of &amp;ldquo;Worse is Better&amp;rdquo; というのを2014年に書いていて、</description>
    </item>
    
    <item>
      <title>ちょうどいいシリアライザ、FlatBuffers</title>
      <link>https://messagepassing.github.io/008-justright/03-karino2/</link>
      <pubDate>Wed, 20 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/008-justright/03-karino2/</guid>
      <description>ちょうどいいテクノロジ、というのは確かにあって、誰でもぱっとJSON、Markdownまでは思いつくと思うのだけど、その次が意外と難しい。 morritaさんはdataframeを挙げていて、これは確かに何かの基盤になっているとは思うのだけれど、なんとなく自分的にはjsonと並べるとしっくり来ない。
ちょうど良いでしばらく考えて思いついたものとしては、SQLiteがある。PostgreSQLやMySQLがすでにある所で登場したSQLiteは、 そのちょうど良さゆえに普及した気がする。だけれど、そこから特に語る所が無い。ふーむ。
と考えていて、そういえば最近「これはちょうど良い！」って思ったものがあった気がするな〜と考えていたら、 FlatBuffersがそれだったのを思い出した。
ちょうどいいシリアライザ、FlatBuffers FlatBuffersはProtocol Buffersのようなもの。 ようなものってことはどこが違うの？という話になるけれど、自分はProtocol Buffersそんな詳しくないので違いを説明するのは難しい。 ということでFlatBuffersの話だけをする。なお、FlatBuffersとは何か、みたいなことはそんなに語らないので公式ドキュメントでも見てください。
FlatBuffersは凄くシンプルで、大したことをしない。そこが良い。 IDLっぽいものからヘッダファイルが生成されて、FlatBuffersのヘッダと一緒にincludeすれば良い。 リンクしなくて良い。いろいろなIDEのプロジェクトファイルと付き合わなくてはいけない自分の環境では大変うれしい。 生成されるファイルも単純で（比較的）小さい。読めばだいたい理解出来る。
メモリ上にすでにデータがあれば、そこからunpackして二重に持ったりしたくない、 オフセット指定してアラインとかエンディアンとか気にせず読み書き出来るくらいのに毛がはえたくらいでいいんだよなぁ、 生成されるenumとかはそのままenum classとしてC++で使えてさぁ、 フォーマットもそんなにかっちりしすぎず、フィールド足すくらいならデフォルト値で読めるくらいで昔のもそのまま読めて、 適当に手作業で必要な所だけ読んだりしたい、 でも配列とかは使いたいし文字列はいい感じに読めてほしい、 でも変な不定長とか要らないので読み飛ばしは簡単に出来てほしい、 みたいな、「こんなもんでいいんだよ」という思いに、ちょうど答えてくれるくらいの複雑さ。
使い方もそれなりにシリアライズの都合に合わせて出来ないこともあるのだけれど、 変にドキュメントできっちり仕様とか説明せずに、都合が悪いような使い方をするとassertで落ちる。そこをデバッガで見ると長々とコメントで何故ダメなのかが書かれていたりする。 そうそう、こんなもんでいいんですよ。
すでにある物を小さくして作るカッコよさ PostgreSQLやMySQLがある所でSQLiteを作る、とか、Protocol Buffersのある所でFlatBuffersを作る、 というのは、難しいですよねぇ。 あとから小さい物で市民権を得るのは、「より労力を集めた」では無く、センスで勝負している感じがかっこいい。 どうやったらそれが出来るのか？はちょっと難しすぎる気がするので、代わりになぜFlatBuffersを使う気になるのか？を、半歩離れて見るくらいをしてみたい。
FlatBuffersが凄くいろいろな所で使う気になるポイントの一つに、手書きで書いてもだいたい同じ感じになるだろうな、という気がするというのが挙げられると思う。 手書きとの差分としてのゼロオーバーヘッド感というか（FlatBuffersは厳密にはゼロでは無いけれど）。 手書きで書いてもたぶんあんまり変わらないので、手書きの所は全部これでいいか、と思える。 だからちょっとしたものでも少し大きいものでも、なんでもかんでもFlatBuffersにしよう、となる。 最近自分はバイナリフォーマットは全部これでいいんじゃないか、と思って積極的に使っている。
ライブラリにはゼロコストで出来る範囲のことをする、という生き残りの道が一つあるよなぁ。 それでは、ある種の「良くあるがいつもでは無いユースケース」でサポート出来ない物が出てくるのだけれど、 それはライバルのライブラリに任せれば良い。ゼロコストの範囲にとどまる事で必ず一定の需要はあるし、ライバルと差別化出来る。 ゼロコストの範囲で出来る事は限られているのでどんどん機能が複雑になる事も無い。
といっても、こういうのは実際に作って市民権を得る所まで行かないと、作るという選択の正しさを証明は出来ない気がする。 すでにあるのを使わずにダメに再発明しているのとの区別は結果でしか出来ないよなぁ。
 morrita FlatBuffers は Protobuf に比べて小さいだけでなく速いという明確な利点があるのが強いですね。 それがつまりゼロコストということなのだろうけれど。 Apache Arrows が採用しているのを見た時はちょっとびっくりした。
ただ X より速い X の代替品 Y は沢山あるけれど必ずしも流行るわけではないから、そこには crack すべき code があるのだろうなあ。
  </description>
    </item>
    
    <item>
      <title>モノレポやったことない</title>
      <link>https://messagepassing.github.io/007-repo/04-kzys/</link>
      <pubDate>Wed, 20 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/007-repo/04-kzys/</guid>
      <description>私が仕事で開発している firecracker-containerd は、
 自分たちのチームが開発している Firecracker Go SDK 同じ会社だけど時差もある別チームの開発している Firecracker Cloud Native Computing Foundation の containerd Open Container Initiative の runc  を使っていて、これらは当然のように別のレポジトリに入っている。オープンソースでない社内のコードも、2019年の Interconnecting Code Workshop のショートペーパー、The Issue Of Source Code Repository Management In Large Enterprises で触れられているように、基本的にはモノレポではない。
というわけで、私はモノレポをやったことがない。モノレポの利点とされるものについては、Envoy の Matt Klein が Monorepos: Please don’t! で細かく反論していて、それならこのままやり過ごしてもいいかなあと思っている。
検索なんてすぐに git grep には任せられなくなって、どうせインデックスが必要になる。コードレビューは空気を読まずによそのチームに出せばいい。インフラやツールの統一はバージョン管理システムの仕事じゃない。別にモノレポじゃなくていいんじゃない?
ビルドナンバーのない世界 Matt Klein もふれているけど「このリビジョンから API 変更するけど、呼び出してる場所も全部変えといたから、あとは心配しないでね」というのは、全体をリンクしてビルドナンバーがついたバイナリがリリースされるようなソフトウェアではできるだろうけど、マイクロサービスで、サービスの境界をまたぐ変更だったりすると、途端に難しくなる。
The Amazon Builders&#39; Library にある Automating safe, hands-off deployments で詳しく説明されているけれど、会社での本番環境へのデプロイは、安全を確保しつつ、継続的・自動的に行われるようになっている。達成度にはチームによってばらつきがあったりもするけれど、目指すべきゴールはここ。
結果として何がおこるかというと、あるサービスのデプロイと、それを呼び出す別のサービスのデプロイを揃えるのは難しくなる。最初のほうのリージョンでは揃うかもしれないけれど、後半のリージョンではそろわないかもしれない。揃っていたと思ったら、どこかで片側だけロールバックされるかもしれない。ひとつのリージョン、ひとつのロードバランサーだけをみても、デプロイ中は新旧のバージョンが混在することもある。
こうなってくると、全てのサービスがひとつのレポジトリに入っていて、アトミックな変更が出来たとしても、そのアトミシティはデプロイ中にバラバラになってしまう。我々の世界にビルドナンバーは存在しないのだ。
もしかしたら Google や Facebook には、そういうアトミシティを担保する何かハイテクがあるのかもしれないけれど、でもまあ、無くてもいいハイテクは無いままでもいいかなあ。</description>
    </item>
    
    <item>
      <title>モノレポ好きじゃない</title>
      <link>https://messagepassing.github.io/007-repo/03-morrita/</link>
      <pubDate>Wed, 20 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/007-repo/03-morrita/</guid>
      <description>自分は今は社内 Monorepo での作業がメインで、たまに Android とかさわってる。 レポジトリの壁というか、レポジトリの違いを含むインフラの違いの壁は、組織の壁より厚い。 この話は前にも書いたことがある。 だから向井さんの言っていることはよくわかる。 Monorepo が強制するインフラ共通化が押し下げた組織の壁の低さを、しばしば実感する。
たとえば最近だと、仕事でやっている Android アプリの APK のビルド方法が変わった際にビルドツールチェインにあるマイナーなバグにあたってしまい、 そのツールのバグを直したことがあった。そんなツールがあるとは知らなかったというくらい降って湧いた話。 でもビルドシステムが統一されているおかげでコードをビルドするのもテストするのも簡単で、 IDE も普段の設定そのまま。コードレビューもいつもと同じ。 はじめてのコードベース、レビュー相手のこともそのチームのこともなにもしらないが、つつがなくしごとが片付いた。
一方、自分が仕事で関わっている電話機の、仕事で関わっているカメラ固有の機能 (HAL) のコードを直したいとなるとすごい大変。 まったく別カルチャー (Android) の、わけのわからないビルドシステムの罠をくぐり抜け、コーディング規約ふくめ全然違うコードを睨み、 いじっていたブランチが間違っていることに気づき、コードレビューをアップロードする方法もわからず、 そもそも git rebase ってどうやるんだっけ・・・みたいになる（最後のは自分が悪い）。 組織的には隣接チームだしレビュー相手も面識あるけど、そういうの関係なくつらい。
Monorepo のいやなところ 1 - 統一されすぎ と利点は享受しつつ、個人的にいまの Monorepo はそんなに好きじゃない。
好きでない理由のひとつめは、自分のいるプロジェクトであるモバイルアプリが、Monorepo 住民のメインストリームではないこと。 この Monorepo のメインストリームは C++ なり Java なり Go なりで RPC のサーバを作る人々である。 JS (今は TS) なフロントエンドも、まあまあ歴史がある。それらと比べるとモバイルアプリ勢は人口も少なく歴史も浅い。
Monorepo の結果として利用を強いられるビルドシステムや CI/CD などのインフラもそれを反映している。 たとえば Bazel というビルドシステムは、モバイルで必須のクロスコンパイルがいまいち得意でない。 ホスト側でツールをビルドして、そのツールを使ってコードを生成して、それをデバイス向けにコンパイルみたいなのが、 できるけどぎこちない。Bazel の全体としての洗練度を考えるとぎこちなさが際立つ。 コードレビューツール付随の静的解析も、Android で使えない Java の API とかを勧めてくる。知らん。 CI/CD も毎週毎日バイナリをプッシュするサーバの人々向けにごく短いブランチ寿命を想定している。 自分のやってるアプリとか二ヶ月に一回もプッシュしないのでブランチも長生きで大量に cherrypick する。 CI ツールの Web UI が爆発気味。</description>
    </item>
    
    <item>
      <title>ちょうどいいインターネット、Gemini</title>
      <link>https://messagepassing.github.io/008-justright/02-kzys/</link>
      <pubDate>Tue, 19 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/008-justright/02-kzys/</guid>
      <description>個人的には TOML は「ちょうどいい」かなあ。YAML の大変さがなくて、Dhall ほど野心的ではない。言われてみると、TOML の作者も GitHub の共同創業者の一人なので、だいぶ有名人ですね。
ちょうどいいインターネット、Gemini 私がここ一年くらい気になっているプロジェクトに Gemini がある。Gemini は Gopher と Web (HTML + HTTP) のいいとこどりを目指すプロジェクトで、行志向のワイヤープロトコルと、その上にのる、これまた行志向の text/gemini フォーマットで構成されている。
ここでいう Gopher は、Go のマスコットではなくて、1993年発行の RFC 1436 で定義されている、Gopher プロトコルのこと。世の中は広いもので、2021年の今現在も Gopher を使っていたり、それでブログのようなことをしている (ブログは Web + Log の略称なので、Gopher 上のブログは Gopher + Log を略して Phlog と呼ばれる) コミュニティが存在している。その中の一人 solderpunk が、Gopher の欠点を克服しつつも、Web よりもずっとシンプルなプロトコルとして設計したのが Gemini だ。
Web の複雑さがなぜ問題なのか? Project Gemini FAQ では、こう説明されている。
 Modern web browsers are so complicated that they can only be developed by very large and expensive projects.</description>
    </item>
    
    <item>
      <title>モノレポは良いもの</title>
      <link>https://messagepassing.github.io/007-repo/02-jmuk/</link>
      <pubDate>Sun, 17 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/007-repo/02-jmuk/</guid>
      <description>参加する会社ごとにレポジトリが分かれたり、チーム単位で別のレポジトリになるのって、コンウェイの法則っぽいですね。わたしはモノレポは良いものだと思っているので、どういうふうになっているかという話をざっと概観したい。
広く知られているようにGoogle社内はモノレポになってて、だいたいのプロジェクトはこのレポジトリにすべて入っている（例外はあるけれど）。で、実際どんなもんですか、という話についての雑感でいえば、モノレポはわたしのような末端の従業員にはけっこういいものだと思っている。
いろいろメリットがあると思うけれど、インフラというかコアの部分を共通化できるというのが大きい気がする。様々なユーティリティは一箇所にまとまっていて再発明をする必要がない（再発明をする楽しみがない、という面はあるかもしれないけど）。GoogleエンジニアといえばProtocol Buffersを詰め替える仕事だという自虐ネタがあるけれど、それほどまでにProtocol Buffersが広まり、使われているのもモノレポゆえだろう。ビルドシステムも共通。こういうのは、いろんな問題を簡単にする。たとえばサービス間のトレースを取るようなユーティリティを作りたくなっても、Protobufのことだけを考えておけばいい。などなど。
コア部分を開発するエンジニアとしても、モノレポの利点は非互換な変更を入れやすいことだと思う。このリビジョンからAPIはこう変わりました、というアナウンスを一本入れる。使ってるところがあっても全部変えればいいだけ。レポジトリが分かれていたら、ユーティリティのバージョンを上げるだけで根回しが必要だったりするし、面倒くさい。コンポーネントごとに依存するライブラリ（たとえばJSONパーサ）やそのバージョンが違ったりして、それで微妙なバグが特定のコンポーネントにだけあったりとか。
モノレポでない世界 つまり、モノレポでない環境の場合、それぞれのレポジトリのあいだの同期を取る必要がある。AndroidやChromeOSはrepoという独自のスクリプトを使って実現している。Bazelのworkspaceで頑張っているプロジェクトもある。でなければgit submoduleという手もある。この辺はずいぶんいろいろ整備されてきたので、だいぶ改善されてるように思うが、いずれにせよメンテナンスのコストがあり、それぐらいならモノレポのほうがいいんじゃないか、という気がする。そういえばIstioというGitHubメインのプロジェクトの仕事をしていたときは、各コンポーネントごとにレポジトリが分かれていたが、レポジトリ間同期の問題に悩まされていた。誰かがrepoを使おうと提案したりして、やめてくれと思った覚えがある。いまはモノレポ化したようだ。
モノレポにはレポジトリに誰が書き込めるか、というコミット権限の問題もある。ふつうにレポジトリが分かれている場合、レポジトリの切れ目がオーナーシップの切れ目になっていて、このレポジトリに書き込めるのは（あるいはapprovalを出せるのは）このチームの人たちだけ、みたいになっているだろう。圧倒的にわかりやすい。あと管理が楽。
モノレポだとこういうことはできないので、何らかの仕組みを導入する必要がある（もしくは、プロジェクト参加者は誰でもオッケーのカオスを受け入れるか、優しい独裁者がすべての権限を握るかだ）。Googleの場合、OWNERSファイルというファイルによってapprovalの権限が記述されている（これはChromiumにも踏襲されている）。OWNERSはたんにファイルというだけではなくて、実際にコミット権限を制限している。つまり、基本的には直接コミットは禁止して、なんらかのボットやCIを経由したコミット以外は通さないようにするということだ。これについては、何らかの仕組みを構築する手間がある。
モノレポの維持コスト Googleのモノレポがどれぐらいヤバいのか、という点については、一般の利用者である自分からははっきり言えないところがある。が、その維持コストは相当のものなはずだ。
たとえばその傍証としては、もともとPerforceを使っていたのにスケールしなくなったから社内専用のバージョン管理システムを独自に作っちゃう、みたいなことをやってしまっているというのはあるだろう（facebookもMercurialを魔改造していると伝え聞く）。会社が大きくなってきてもモノレポを維持したいなら、どうしてもそういうことは起こる。
あとたとえば、そもそもGoogleの社内レポジトリはレポジトリ全体をチェックアウトしたりできないので、部分的に開発に使うところだけチェックアウトしている。それでもうまく動くような様々な仕組みもたくさんある。そういうのの開発コスト、超大変そう。そこまでして社内全体でモノレポを維持するメリットはあるんだろうか？　まあ「ある」と誰かが判断してるからそうなんだろうけれど。
まぁこの辺は想像するだけでやばそうだなと思うし興味深くはあるけれど、一プロジェクト内でレポジトリを分けるかどうかという話とはあんまり関係ないな。
さて、いろいろ書いてみたけれど、私はけっこう社内レポジトリの経験は大昔にしかない。最近は社内レポジトリでないプロジェクトばっかりやってるから、今は社内の実情がわかってない面があるかもしれない。たとえば、昔なら社内レポジトリの大半はようするにみんなWebサーバだったり社内RPCサーバを作ってるだけだったけど、今はそうでもないだろうという話もあるだろう。そこんとこどうでしょう＞もりたさん
 morrita Facebook の Mercurial Monorepo, 2014 年のアナウンス以降どうなったのか眺めてみたら EdenSCM という名前で Rust でバックエンドサーバを書き C++ で Fuse を書きと楽しくやってるようですね。
詳しいことは知りませんが Facebook による Mercurial の拡張の成果は Google も部分的な恩恵に預かっていて、 おかげで最近は Perforce でなく Mercurial のフロントエンドを使って仕事をできるようになりました。個人的にはここ五年くらいで一番の社内革命。
  karino2 Rustでバックエンド、C++でFuseってすごいね。Facebookはいろいろ作るよなぁ。カルチャーなのかね。</description>
    </item>
    
    <item>
      <title>ハイテクないので昔話を</title>
      <link>https://messagepassing.github.io/006-hitech/04-kzys/</link>
      <pubDate>Fri, 15 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/006-hitech/04-kzys/</guid>
      <description>私もみなさんと同じで、自分でハイテクを書く機会というのはほとんどない。隣のチームの Firecracker はハイテク感があるけれど、QEMU の Tiny Code Generator の話 なんかに比べるとずっと平和で、別のアーキテクチャのエミュレーションをがんばったりはしない。
社内を見渡すと、EBS の Physalia なんかは、自分のチームとの距離の遠さも手伝って、だいぶハイテク感がある。これは morrita さんの書いていた「巨大製品の中で使われる、ドメインに特化したものを作る、組織戦のハイテク」だと思う。
2000年のハイテクと、2020年のハイテク 「Berkeley DB のようなものを再実装」と言われて思い出すのは Tokyo Cabinet のことで、そう考えると2000年初頭にミクシィで働いていたころには、C/C++ なミドルウェアが突如としてプロダクションに導入されることが時折あった。
ミクシィの全文検索は Hyper Estraier そのままではなかった気がするけど、KVS の Tokyo Tyrant はそのまま使っていたし、非同期実行の仕組みは、MySQL を分散キューにする Q4M がベースになっていた。GREE には KVS の Flare が、DeNA には MySQL の SQL 部分を迂回して NoSQL 風に使う HandlerSocket があった。
2020年代にこういうソフトウェアを作る機会はなかなかない。これには、オープンソースの既存実装の充実にあわせて、クラウドの発展もあると思う。自分で MySQL を運用していた人が、改造された MySQL を運用するときのギャップに比べると、Aurora みたいなマネージドなデータベースを使っていた人が、改造された MySQL を運用するときのギャップは大きくて、だいぶ頑張らないと説得しきれない。
アプリケーションを作る人々がビジネスロジックに集中できるのは良いことだし、私は AWS 勤務なので滅多なことは書けないけれど、でもまあちょっとの寂しさは感じる。
新しいプログラミング言語と再実装 そういえば、containerd では Berkeley DB の代わりに bbolt というのを使っている。
新しいプログラミング言語とそのコミュニティでは、C/C++ を呼び出さない &amp;ldquo;pure XXX&amp;rdquo; な実装が欲しいという需要がある。Ruby や Python だと、そういう実装は「遅いけれど、インストールが簡単」くらいのところに落ち着きがちだけど、Go なら十分に速い実装を書けるかもしれないし、Rust なら C/C++ から呼び出されるのも夢じゃない。Rust のパーサコンビネーターである nom の作者の論文、Writing parsers like it is 2017 (PDF) でも、VLC の FLV パーサーを Rust で置き換えたりしていたし、curl には Rust バックエンドが入るらしい。</description>
    </item>
    
    <item>
      <title>ちょうどよさのはなし</title>
      <link>https://messagepassing.github.io/008-justright/01-morrita/</link>
      <pubDate>Thu, 14 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/008-justright/01-morrita/</guid>
      <description>その「ちょうどよさ」ゆえに普及したテクノロジ - アイデアや標準があると思う。 そういうのは、科学や工学でなく匠としてのプログラミングを表している気がして成功が嬉しい。
自分にとって「ちょうどいいテクノロジ」の代表は JSON (2002) と Markdown (2004). どちらも技術的にはさほど大したことはないけれど、どちらも広く使われている。
「ちょうどいいテクノロジ」はこれ以前にも色々あった。UNIX(1969) や HTTP/REST (1991) なんかが思い当たる。 ただ同時代性がないせいか成功が華やかすぎるせいか、まいち親近感がない。 ついでにいうと、自分はもはやこれらに「ちょうどよさ」を感じない。 UNIX の代表 Linux は超巨大ソフトウェアだし、HTTP の最新版 HTTP/3 は随分複雑なプロトコルに見える。 JSON と Markdown は、今のところ当初の「ちょうどよさ」を留めている、気がする。 UNIX と Markdown を並べると怒られちゃいそうだけど、別に UNIX がだめって話じゃないんだよ。 自分にとって「ちょうどよさ」の範疇にないだけで。
「ちょうどよい」テクノロジの成功はよく Worse Is Better として説明される。 間違ってはいないだろうけれど、テクノロジの市場が scarcity から abundance にシフトする中でこの説明が十分な力を持っているとも思えない。 たとえば JSON 的なものは YAML なり TOML なりいくつかあった。Markdown にもライバルは沢山いた。 （自分は当時 Textile に肩入れしていた。RST は今でも現役だ。) これらはどれもまあまあちょうどよかったはずだけれど、JSON や Markdown の成功には及ばなかった。
何が違ったのだろう。たとえば Markdown の発明者が John Gruber や Aaron Swartz のようなインターネット有名人だった事実は、どのくらい成功を助けたのだろう。 あるいは JSON が JS のサブセットなのはどれくらい重要だったろう。 そういえば JSON の Douglas Crockford も有名人だ。</description>
    </item>
    
    <item>
      <title>案外やってないなという感じ</title>
      <link>https://messagepassing.github.io/006-hitech/03-shinh/</link>
      <pubDate>Thu, 14 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/006-hitech/03-shinh/</guid>
      <description>ハイテク @Google ハイテク、グーグルにいた時の感覚は morrita さんに近い。「面接の時はアルゴリズム問題とか聞くけど、実際仕事で難しいアルゴリズムとか書いてないよね、簡単な再帰すら書かねーよな」みたいな雑談をよくしていた。11年くらい勤めて、あれはハイテクだったなーと思う自分の作業は 2,3 くらいで、期間としては合計半年から一年くらいじゃないかな。
割と、それで良いのだと思っている。5割の力で、余力を残して働くのがプロじゃないかと。余力があるくらいでできたプロダクトの方が、完成度が高い。持てる技術ギリギリを使って書いたコードは、たぶんバグってるか、開発に時間を使いすぎているか、悪いとその両方。
いざとなれば難しいデータ構造を使いこなすことも、超絶技巧の高速化もできるかもしれないけど、別に困ってないのに導入されたハイテクは単にメンテ性を落とすだけ。普通のコードで要件を満たせるのであればそれでいい。いざとなった時にハイテクができる牙を研ぐのは家でやればいい。その牙を使う日が来るのかは知らないけど。
ハイテク @PFN PFN に転職して、 PFN は零細企業や小規模スタートアップというほど小さい会社ではないけどなんだかやたらと多角的に色々やってるので、一人当たりの守備範囲は零細と大差ないんじゃないだろうか。入社して言われたことを要約すると「TensorFlow XLA の汎用性増やしたみたいなの作ってね、人員は一名。あ、インターンが一人いるよ」みたいな感じ。さあ大変だ、というか、できるわけないだろ！
できるかはともかくとして、これは楽しい。でも「ハイテクを一人占めするベテランはもういない、ハイテク祭りだ！」となってるかというと、あまりなっていない。自明にやるべきこと、ハリボテでいいから存在しないと話にならないコンポーネントが多すぎて、何を作っても「とりあえずここはこれで動くには動く……あとでもっとかっこよくしたいけど、もっとやるべきことがあるので、次に行こう」となる。それはそれで楽しくはある。
ベースライン 最近では「落ちついたらここは僕のハイテクですごくするんだ！楽しみだなあ。論文とかも参考にしちゃうぞ」と思っていたところを人に譲るというのが何度も起きている。いくつか例があったんだけど、 karino さんが最初に計算グラフの話をしていたので、それ系の話をしてみる。
計算グラフのスケジューラは topological order を満たしていれば計算順序を自由に変えていいのでなるべく速くなるように並べましょう、という問題。 DRAM が相対的に遅いので SRAM にあるデータをなるべく使いまわせる計算順が良くて、使い回せない時にどれを spill するかを賢く選びたい。最終的にはメタヒューリスティクスでも導入しましょ、という話をしてたんだけど(これはかなりハイテクぽくない？)高速に動作する貪欲のベースラインは欲しいので、とりあえず適当なのをでっちあげた。
計算順序はテキトーなヒューリスティクスで決めて、 SRAM が足りなくなったら spill する感じ。 DRAM と SRAM とか言うとソフトウェアエンジニアは構えてしまうけど、キャッシュから何捨てる？みたいな話なので、まあ LRU でしょとテキトーに最近使ってないのを捨てるつもりのコードを書いた。そのあとハイテクメタヒューリスティクスやるぞ、てことまで手が回らないうちに他のことやった方が良い雰囲気になってたので、アルゴリズム強いってウワサの人に譲ることにした。（強いってどんくらいなんだろ、と後から競プロサイトで検索してみたら、なんかちょっとドン引きするくらい強かった。）
その競プロすごい人は、なんだかすごい速度で僕の実装を改良再実装して、そこからさらに進めて当初予定していたメタヒューリスティクスまで実装してくれて、実際に高速化を達成、さらなる改良に従事している。ついでに「LRU は未来がわからない時に有効なオンラインアルゴリズムであって、将来の計算が静的にわかってる状況では単に最も遠い未来で使うやつ捨てれば良いことが知られてますよ」と指摘してくれたし、さらに言うと僕が LRU だと思っていたものはそもそも LRU になってなかった。
「後で自分でやろうと思って、それを楽しみにそこまでの道の整備をしたのにな」という気持ちも少しある。でも他の人にやってもらってみると、スケジューラの例のように、正直自分でやってたらここまで良くならなかったなと思うことがほとんどだし、労せず成果物ができているのだからまあいっか、となっている。
大企業を出て、今一緒に作業してる中ではたぶん僕が一番ベテランだし、ハイテクをやる権利も機会もあるのだけど、案外やってないなという感じ。立場とか環境とか機会とかもあるんでしょうけど、人に依存するする面も多いんでないかな、と。
 morrirta ここでいうベースラインは自分からみるとだいぶハイテクなので、 ハイテクの期待値は個人差がありそうですね。 プログラマにとってハイテクなコードとは「背伸びしたコード」なのかもしれない。
それはさておき難しいコードを競プロ勢に任せるの、すごいわかる。 ただ東京にいた頃は競プロ勢いっぱいいた気がするけれど転勤したあとすっかり見なくなりました。 気づいてないだけでみなやってるのかもしれませんが。
  shinh 日本、 OSS とかに参加するには英語のバリアが厳しいので競プロが流行る、みたいな仮説を持っています。もちろん公平な評価と明確な得点を好むとか、他の要因も色々考えられますが……</description>
    </item>
    
    <item>
      <title>モノレポのはなし</title>
      <link>https://messagepassing.github.io/007-repo/01-karino2/</link>
      <pubDate>Sun, 10 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/007-repo/01-karino2/</guid>
      <description>モノレポについて経験豊富そうな皆さんの話を聞きたい。 まずはその背景から。
会社で分かれるレポジトリ フリーランスをやっていると、たまにいろんな零細企業を集めて一つのサービスを作る場に遭遇する。 人を集める時に、一つの会社だけじゃなくて複数の会社が集まることがよくある。 たとえばマーケティングが強みの会社が自社ではエンジニアを持っていなくて、開発は外部の人たちを集めてやるみたいな。 しかもそれぞれの会社からは一人とか二人だけしか来ないので、 6人の小規模なチームなのに会社は4つあるとかいう状況になったりもする。
そうすると何が起こるかというと、レポジトリが会社ごとに分かれたりする。 「クラウドとフロントの間はAPIを決めましょう、 それでクラウド側がバイナリをリリースして、フロント側がたまにそれをマージしましょう」みたいなフローになる。フロントとバックエンドなんて関わっているのは3人しか居なくて、コードの規模も凄く小さいのに。
酷い時にはフロントはバックエンドのコードが読めないとか変更出来ないとか、そんな事態になったりする事もある。 そこまで行かなくてもレポジトリは触らせてくれないくらいは良くある。
ログや履歴が見れないデメリットは説明するまでも無い。 あとはAPIの変更が無駄に難しくなるし、お互いソースが読めないと継ぎ目の所ですぐバグったりするし、バグを追うのが無駄に大変だったり。
しかもレポジトリが分かれていると、手動でコードを持っていってマージするみたいなのをえんえんやる人が発生したりもする。 お前6人しか居ないプロジェクトで一人それかよっ！（この物語はフィクションです）。
レポジトリを一つにしようという意思 この手の開発でレポジトリが分かれるのは、実に些細な理由である事が多い。 ソースコードを見せない理由も実際はほとんど無くて、ちゃんとその辺を話し合って決める人が居なかったので念の為（？）見せない事にしたとか、その程度。 もともと寄せ集めで開発するケースでは、力関係的にプロジェクトを立ち上げる会社がだいたい凄く強いので、ちゃんとその会社が望めばレポジトリは一つでソースコードも全員が見える状態に出来る。 でも、プロジェクトを立ち上げる会社が開発以外の所に強みを持つ会社だと、そうした方針について強い意思を持っていなかったりする。そうすると些細な理由でなんとなくレポジトリが分かれてしまうのを防げない。
分かれる理由が些細であっても分かれた影響はでかい。 レポジトリが一つかどうかとかソースにアクセス出来るとか、開発効率には大きな影響を与える。 少し話し合いを頑張れば劇的に改善出来るのだから、頑張った方がいいのは間違いない。 だけれども些細な障害を乗り越えてレポジトリを一つにする為には確固とした意思を必要とする。 そうした強い意思を持つためにはしっかりとした「あるべき姿」が見えている必要があると思う。 でもフリーランスになってTech企業の外に出てみると、 そうした姿は意外と知られていないと感じた。
自分はどこでそうした「あるべき姿」を学んだのだろう？ 自分の場合を思うと、自分はモノレポ的な経験から学んだ気がする。
自分のモノレポ的な体験 自分の経験は厳密な意味ではモノレポでは無くて、その辺が今回皆さまに見解を聞きたいと思った所でもある。 でもまぁまぁモノレポと言っても良い経験はあるので、その辺の話を。
自分が一番モノレポに近い環境だったのは、MSでOfficeのチームだった時。 OfficeはOffice全体で一つのレポジトリだった。会社にはOfficeの他に（雑にいえば）WindowsとVisualStudioがあって、それらは別のレポジトリだった。厳密な意味ではモノレポでは無い。 （10年くらい前の話で、モノレポという概念もまだ無かったと思うし。） ただ、Officeの中にはWordやExcelなどの他にも、OutlookとかSharePointのようなサーバーサイドなどだいぶ他とは毛色の違う物も混じっていて、 それらが一つのレポジトリで開発されているのは当時それなりに衝撃だった。
ローカルに無い状態で全部syncすると３日くらい掛かるとかいう世界だったので、それなりに巨大なコードベースでもあった。 ローカルにある状態でもsyncはめっちゃ時間掛かるので、家に帰る前にsyncする風習になっていた。syncのコマンドを実行すると最初にネットワークなどのエラーが無い事を確認して、ここからは時間がかかるという所まで行ったら「もう家に帰ってもいいですよ」とビープ音が鳴ったりする。
当時の環境がモノレポ的だと自分が思う事の一つに、独自のツールが充実していた事が挙げられる。 例えばレポジトリの検索ツールがあって、 ローカルにコードが無いプロジェクトも、コマンドラインからローカルにあるかのように一括検索が出来た。 新しいAPIの使い方や言語機能の使い方はとりあえずレポジトリを検索してみて他のプロジェクトを参考にしたりしていた。
また依存が他のチームにまで及ぶ場合、自分が他のチームまで含めて全部を変える事が出来た。 もちろんレビューとかは必要だけれど、皆が同じレポジトリを使っているので、 チームごとの別々のツリーに入れなくてはいけないみたいな作業は無かった。 関係無いチームも全部コードにアクセス出来るのはモノレポ的だと思う所だ。
あれだけのレポジトリのでかさを維持する為には、凄まじいエンジニアリングコストが掛かっていた。 そんな膨大なコストというのはまさにモノレポの欠点でもあるのだけど、 プロジェクトのいろいろな事を決める人たちがそれだけのコストを払ってでも維持するだけのメリットがあると思ってくれていた訳だ。
実際欠点もあるにせよ、当時あの規模の開発を行う為にはレポジトリを一つにするしか無かったと思う。 ツリーが別だったら、あっという間に置いていかれてしまって永遠にマージが終わらないに違いない。 実際ツリーが一つでもcommitは凄い大変だったし。
モノレポってどうなんでしょう？ 冒頭に述べたようなプロジェクトだと、 何故か自分がレポジトリやブランチマネージメントの基本的な事をレクチャーしたりする事もあるのだけど、 この手の事は実体験が無いとうまく伝えるのは意外と難しい。
一般的には、モノレポの功罪とかって、 最近だとGoogleとかFacebookのモノレポなどの議論で学ぶ事だと思う。 でもその辺の話が好きなのはその辺の経験をすでに持っている人ばかりで、 意外とその辺の常識が共有されているのは、狭い世界だけだった。 そんな事にフリーランスになって初めて気づいたりした。
そうした時にFacebookとかGoogleのモノレポの記事にリンクを貼ってもいいのだけど、 記事は記事なのでやっぱり一面的というか、説得力が微妙。 もうちょっと実体験に基づいた話がある方が良い。
さらに、Googleのモノレポはおそらく当時のOfficeよりは遥かにでかくなっているはずなので、 ヤバさもずっと上になっているはずだ。 そうした経験があると自分とは違った見解もありそうで、自分個人としても聞いてみたい気がした。</description>
    </item>
    
    <item>
      <title>ブックマークしたい</title>
      <link>https://messagepassing.github.io/005-bookmark/04-kzys/</link>
      <pubDate>Sat, 09 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/005-bookmark/04-kzys/</guid>
      <description>みなさんありがとうございます。
自分も jmuk さんと同じ「虚無」に落ち着いてしまったのですが、昔はもうちょっとちゃんとしてたんですよね。どこからこうなったんだっけ。
虚無への道 最初に、ブラウザのブックマークの後に使っていたのは、今は亡き del.icio.us だった。その後に、はてなブックマーク に移ったのは、なんでだったっけ?
でも、しばらく使って思ったのが
 Go についてブックマークしたページに &amp;ldquo;go&amp;rdquo; とタグをつけるのは間違っていて、全文検索で解決するべき 言いたいことがあったらブログに書くなりメールを送るべきで、ブックマークでワイワイするべきではない  で、タグをつけるというアイデアと、ソーシャルなブックマークというアイデア両方になんとなくしっくりこなくなってしまって、現在に至る。
karino2 さんと morrita さんと同じように、仕事だと雑多なノート兼 TODO リストみたいなものを Quip に作っていて、そこにブックマークも行きがち。
仕事の外でもそうしたらいいかなと思って Evernote にノートを作ったりしているけど、いまひとつ定着しない。これは morrita さんの
 昔は Evernote とか org-mode のいわゆる journal に記録をつけていた時期もあったけれど、定着しなかった。Fragments は「友達に送る」という口実が少しは支えになってる気がする。
 これと同じ問題そう。一方で、結婚して子供ができてから、公開したくない/する必要がない情報がだんだん増えてきているので、公開することで何かを担保するのもなあ。Sharenting したくない。
とりあえず今年は Evernote か Scrapbox でやってみます。</description>
    </item>
    
    <item>
      <title>読むものさがし</title>
      <link>https://messagepassing.github.io/009-feed/01-morrita/</link>
      <pubDate>Fri, 08 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/009-feed/01-morrita/</guid>
      <description>時間および精神的余裕のなさもあり、ここ数年あまりオンラインの技術読みものを読んでいない。というか真面目に探してない。 オンライン読みもの流通の場は時とともに移り変わるので、置いていかれている感がある。 わかってはいたけれど、みんな何読んでるのかなと気になりはする。
というわけで、皆様が何を読んでるのかきいて周るターンです。 手始めに自分の話をちょっと書いてみたい。
読んでいないもの そもそもの話のきっかけとして、自分は宗教的理由などからあまりソーシャルメディアを見ないようにしている。 （ソーシャルブックマークの類はトップページだけぼちぼちひやかすかんじ。以前はこれもやめていたが今は息抜きとして受け入れている。） おかげで時間を溶かす量は昔より減って、心も平安。けれど先に書いた置いてかれる感に繋がってもいる。
RSS ソーシャルメディアやソーシャルブックマークのような無限にリンクが振ってくるメディアのかわりに、 昔ながらの RSS は購読数を絞りつつ今も使っている。 具体的なサービスは Feedbin と Feeder を使っている。Feedbin には金を払っている。
ともだちフィード 二つ RSS リーダーを使っているのは、知り合いのブログなどをそれ以外の世間から分離するため。 自分にとって知り合いの blog は social media みたいなもので、ほっこりした気分になりたくて読んでる。 友達の言動というのはと中身によらず「元気にやってるなよしよし」となるでしょ。 そういうのと意識高い engineering blog みたいのが同時に目に入るのは嬉しくない。
この友達 RSS reader には Feeder を使っているのだけれど、Feeder は RSS に加え Twitter フィードもユーザ単位で購読できる。 だからなかなかブログを書かないけど Twitter ではアクティブな友達は　Feeder ごしの Twitter で見守っている。 タイムラインみたいな概念は崩壊するとはいえ、それほど困らない。
なお Feeder の出来は特に良くない。というか悪い。ただ自分がブログや Twitter を読んでる友達なんて 10 人くらいなので、 出来の悪さで困ることはない。(友達の少なさは問題かもしれない。)
ともだち以外フィード そういう友達以外フィードは Feedbin で読んでいる。 友達フィードよりは沢山購読してる。数えてないけど、たぶん 100 くらいだろうか。 ただ基本的には読んでなく、既読にしてるだけ。それが良いことだとは思っていないが、現状そうなっている。 全部読んでいる友達と既読にするだけの友達以外を分離したかったのは、デフォルトの態度の違いもあるかもしれない。</description>
    </item>
    
    <item>
      <title>読んだ本はBlog、Webの記事は適当</title>
      <link>https://messagepassing.github.io/005-bookmark/03-karino2/</link>
      <pubDate>Fri, 08 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/005-bookmark/03-karino2/</guid>
      <description>向井さんのお察しの通り、全公開上等でブログですね。 ブログせずに読んだ本も少しはあるけれど。
このトピックの元だった2020年に読んだ本の話を書いた時は、過去のブログを眺めて、 あとはKindleアプリで他に買ったの無いかなぁ、と軽く確認したぐらいですね。 そういう点ではmorritaさんと似ている。
技術記事の場合、仕事で調査している時は社内のWikiを基本に、 Wikiに書くほどの事でも無い場合はSlackの分報に書いています。 仕事で読む物は記録は必ず残している。
仕事では無く、すぐ読んで終わりのつもりの技術ブログなどは、あまりちゃんと管理してないですね。 だいたいスマホで見かけてBOOXで読む、というパターンが多いので、 スマホからBOOXへはGoogle Driveのテキストファイル(自作メモアプリを使っている)経由か、 Pocket経由で送っています。Pocketは一応あとで以前読んだのを探す事は出来るので、ブックマークも兼ねて使っている。 使い分けには特にルールは無いけど、たくさん送る時はPocket、ちょっとSNSとかで流れてきたのが気になった、くらいだと自作メモアプリですね。
すぐに読む気は無いけど記録として残しておきたいwebの記事には、Google Bookmarksを使ってます。 いつサービス終了するかドキドキしながら使ってますが…必要十分でいいサービスだと思うんだけどなぁ。
論文は必ずGoogle Driveの特定フォルダ下に置く事にして、ちゃんと読んだ物は基本的にはブログを書く、というルールで管理していますね。
たぶん皆もそうだと思うけれど、全体的に昔よりも雑になってますねぇ。 前はもうちょっとちゃんと管理していたのだけれど。
あと誰も興味無いだろうけれど、なろう小説は、なろう公式のブックマーク機能を使っています。最新話を追っかけているものはカテゴリ1、読み終わったものや読むのを止めたものはカテゴリ2、 そのうち読もうと思っているものや読んでいる途中でまだ最新話には追いついていない物はカテゴリ3にしている。
 morrita Google Bookmarks! まだあったのか!! しかも Maps 上で Like した場所のサイトが勝手に追加されている&amp;hellip;
自分も仕事関係で読んだものは、バグトラッカーなり作業記録なりからリンクしてます。あるいはコードのコメントとか、関連ドキュメントとか。 必要性があって読むものは文脈があるから、その文脈に埋め込めばよいよね。
  </description>
    </item>
    
    <item>
      <title>ブックマークはしない</title>
      <link>https://messagepassing.github.io/005-bookmark/02-jmuk/</link>
      <pubDate>Wed, 06 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/005-bookmark/02-jmuk/</guid>
      <description>みんな記録とかどうしてるんだろうっていうのは私も疑問に思ってたところがある（笑）。管理、一切してないというのが一番近いな。管理したほうがいいんだけど……。
紙の本については、書棚の量が今のところたかが知れているので眺めるぐらいでだいたいわかるようになっている。内容についてはだいたい見れば思い出す……というか思い出せないぐらいの本は自分にとって重要ではないっていうことだと思う。
電子書籍は、Amazon Kindleについては提供されているライブラリで事足りる。それ以外のものは、Google Driveにつっこんだりしているけれど、未読管理であるとか、いつ読んだかとか、感想とかは、なんにもしてない。基本的に買ったはしから読み、それで読まなかったものは埋もれていってしまっている気がする。PDFも同様で基本的には散逸しまくっていると思う。ポッドキャストで扱うであろう論文についてはそれだと立ち行かないので、Dropbox paperで読みたいPDFのリストをまとめているけれど、それぐらい。
インターネットの記事のブックマークとかは一層の虚無であり、読み終わったらそれで終わりということが一番多い気がする。あとで読む記事とかは、ブラウザのタブを開きっぱなしにしておいて後日見る、みたいな運用にしている。
という次第で、端的に要約すると、無。読んだものの管理はしていません。自分の記憶力と印象に頼りきりでボーッと生きている。さすがに何らかのものは記録したほうがいい気がしないでもない、と思いつつ、でも面倒だしな、というのを繰り返している。タスク管理もいろいろ試してみたがあんまりうまくいってないし。
基本的なソリューションはブログに書いておくことなんじゃないかと思うけれど、ブログはやっぱりなんか気合が必要になってしまった感がある。そんなにちゃんとした感想を書きたいわけでもないときもある。あと別に公開したくないときもある。というわけでうだう悩んでいる。
twitterはヘビーに使っているけれど、こういう用途には使っていないし向いていない気がするな。twitterをどう使ったとしても記録は簡単に散逸してしまう気がするので。
という本当に虚無みたいな回答になっちゃうんだよな。有野さんは全公開上等でブログっていうスタイルですか？</description>
    </item>
    
    <item>
      <title>Re: Re: Re: 今年読んだもの</title>
      <link>https://messagepassing.github.io/004-whatiread/04-kzys/</link>
      <pubDate>Tue, 05 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/004-whatiread/04-kzys/</guid>
      <description>ここ数年ずっと技術書は O&amp;rsquo;Reilly Online Learning (もう Safari と呼ばないんですね) で読んでいる。ACM の年会費を払うだけで、ちょっとだけ興味があるトピックに関してでも、本を複数冊パラパラと読めるし、O&amp;rsquo;Reilly の本だけではないので、本屋気分で新着を冷やかすのも楽しい。
ただ、高い技術書を買って値段分の価値をとるべく読み切る、という動機が弱くなるという問題があって、ここまでが長い言い訳なんですが、2020年は通読して印象に残っている技術書がありません。2021年はがんばります。
BPF Performance Tools jmuk さんと同じく &amp;ldquo;BPF Performance Tools&amp;rdquo; は途中まで読んだ。構成にはあまり不満はなくて「BPF すごいなあ。便利だなあ。なんでもできるなあ。」という印象。
BPF そのものは、bpftrace で色々書くのも DTrace みたいでかっこいいけれど、BCC に入っている小物スクリプトを使うだけでも結構良くて、昔だったらあたりをつけて strace したり、lsof を連打するような局面で「このホストの全ての open を tail -F 風にずっと流す」みたいなことができて便利。containerd/cgroup のこのバグを直したときにも使ったはず。
Practical TLA+ AWS 社員たるもの PlusCal 経由でいいので TLA+ くらい書けなくては、と思って読み出した。これはまだ本当に冒頭までしか読めていなくて、語るべきことなし。
著者の Hillel Wayne は TLA+ や Alloy など形式手法のコンサルティングやワークショップなどを仕事にしている人で、ブログもある。
Why the Sorbet typechecker is fast Sorbet は Stripe の開発している Ruby むけの静的型チェッカ。初期開発メンバーの一人である Nelson Elhage は、この他にも Sorbet の開発上の工夫について色々と書いていて、どれも面白い。
 Record/Replay testing in Sorbet Reflections on software performance  以前は Scala のコンパイラを書いていた Dmitry Petrashko も Sorbet には関わっていて、Software Engineering Daily ポッドキャストの Sorbet: Typed Ruby with Dmitry Petrashko で話している。</description>
    </item>
    
    <item>
      <title>ブックマークのはなし</title>
      <link>https://messagepassing.github.io/005-bookmark/01-morrita/</link>
      <pubDate>Tue, 05 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/005-bookmark/01-morrita/</guid>
      <description>From kzys:
 みなさんがするすると読んだものを列挙できるのにちょっとびっくりしているんですが、 ブックマークというか、PDF もふくんだ読んだものの管理ってどうしてます?
 そこそこのインターネット中毒者であるところのわたくしから・・・。 といっても家事子守とかがあると管理が必要なほど沢山のテキストを読めないので、今はそんなにがんばってない。
近況ニュースレター ここ二年くらい簡易 journal として Twitter の代わりに Notion や WordPress で箇条書き公開日記みたいな記録を つけてる。一週間で 1 ページ。 Fragments と読んでいる。
この Fragments の中に読んだものへのリンクと感想を並べ、ブックマークがわりにしてる。 これは世間の一部の人が Twitter にリンクを蓄積しているのと似たようなものだと思う。 公開する意義があるのか怪しい内容だが自分にとってはソーシャルメディアなので、 ページを更新するタイミングで友達数人に近況ニュースレターとして送りつけている。 （頼まれもしないのに送ってるのでニュースレターというよりは迷惑メールだけど。）
それとは別に古き良きブックマークサービスの Pinboard もつかっているけれど、 こっちは読んで「ない」ものと純粋に資料的価値のあるものをファイルしておくかんじ。 プライバシー優先のため Pinboard は公開していない。 日本の人だと「はてなブックマーク」とかを使うところだと思う。 Pinboard は特段優れた機能を持つわけではないが、 ソーシャルメディアではなく単なるツールなのでうっかり嫌な気持ちにならない点は良い。
Podcast のために読む論文の管理には Paperpile を使っているが、 自分は別にアカデミアではないので書誌管理機能は活用していない。 付属の PDF ビューアの出来の良さと、論文特化の Chrome extension とかが割と良い。 ただアカデミアみたいに大量に読んでしかも引用するとかで限り Pinboard のような普通のブックマークでダメな理由は無い気がする。
電子書籍類は大して量がないので電子書籍アプリの書棚で足りている。 あと先の Fragments やブログに感想文を書いたりもしている。
こうしてみると純粋に時系列に読んだ記録としては Fragments が一番機能しているかな。こないだの記事を書くのにも見返した。 昔は Evernote とか org-mode のいわゆる journal に記録をつけていた時期もあったけれど、定着しなかった。 Fragments は「友達に送る」という口実が少しは支えになってる気がする。 Twitter や Facebook でダメなのかは個人によると思うけれど、自分は気が散りすぎて無理。</description>
    </item>
    
    <item>
      <title>Re: Re: 今年読んだもの</title>
      <link>https://messagepassing.github.io/004-whatiread/03-jmuk/</link>
      <pubDate>Sun, 03 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/004-whatiread/03-jmuk/</guid>
      <description>いろいろ忙しかったのと、私事などもあり、2020年はあんまりいろいろ読んだりはしない年になった。のであんまり書くことなかったりするんだよなぁ。
reMarkable2 話をふられたのでまずそこから書くと、reMarkable2を買った。e-inkのタブレットデバイス。なかみは独自のOSで、基本的には文書や本を読むためのものというくくり。見かけてすぐ予約したけど、パンデミックの影響もあり、入手したのは10月。まだそんなに使いこなしているわけでもない。
もともとの動機として、論文を読むのに向いてるe-inkタブレットがほしかったのだった。reMarkable2は基本的にはPDFとepubリーダになっていて、PDFとかebookはアプリ・拡張機能からクラウド経由でデバイスに送り込んで読める。その用途なら、Amazon Kindleデバイス＋instapaperでもまぁいいんだけどね……（まあそれなりの大きさがあるのは良い）。
e-inkリーダとしての性能は、まあそこそこかな。やっぱり画面遷移が遅いし、前後のページにしか遷移できないので、いきなり前の方にジャンプしたりできなくて、ちょっと不便。でもやっぱり読みやすい。それと、専用のスタイラスがあって、PDFでもebookでも好き勝手にメモを書き込めるのが面白い。というわけで、論文読みデバイスとしてはなかなか優秀だと思う。でもまあ、向いている人が必ずしも多いわけではないニッチ製品かなぁ。いちおうウェブページも同じ仕組みで（ebookに変換して転送して）読むことはできる。けどまあウェブ閲覧としてはイマイチ。やってみたら日本語ウェブページも読めなかったし（日本語PDFは読めるようだ。フォント埋め込みしてるからかな）。
Let&amp;rsquo;s Encrypt: An Automated Certificate Authority to Encrypt the Entire Web というわけで、reMarkable2で読むのはもっぱら論文なんだけど、読んだ論文は基本的にはポッドキャストで紹介するつもりなので、ここで紹介するものがあんまりない。ただそういえば、このLet&amp;rsquo;s Encryptの論文はおもしろかったけどポッドキャスト向きじゃあないかも。あんまりアカデミックな内容じゃないんだよね。
Let&amp;rsquo;s Encryptのことのおこり、組織構成、資金、クライアントツールのデモグラフィック、成功の要因などが詳しく書かれている。技術面だとLet&amp;rsquo;s Encryptのプロトコルが解説されていて、これでようやくどういうものか理解できたっていうのはある。完全に自動化されていて間に人間がいっさい介在しない（できない）っていうのはやっぱり面白いね。
そういえばLet&amp;rsquo;s Encryptの証明書は有効期限が短く3ヶ月しかない。それはまあちょっと不便なんだけど、なぜそうなっているのか。なんとなく勝手に、完全自動化で無料である意味でほかのCAのような信頼性の担保がないからだとずっと思っていたが、この論文を読んだらぜんぜんそういう理由じゃなかったので、そこは読んでて思わず声が出た。有効期限が短くなれば人間としても手作業で更新するのが手間になるから、ユーザ側も更新をcronなどで完全自動化するモチベーションが出てくる。そうなるようにわざと短い有効期限にしているのだそうだ。そうだったのかよ！？
BPF Performance Tools さて、本でいえばBPF Performance Toolsを2020年初に買っていた。BPFまわりで活発に活動しているBrendan Gregg氏の本だ。めちゃくちゃ分厚い。あと残念な告白をすると、通読はできていません。
買って読んでみてわかったのだが、ある意味では膨大なレシピブックという側面があり、こういうことをしたいならこうする、といったコードサンプル、事例がふんだんに盛り込まれていて、扱われているネタは広範なんだけど、悪くいえば散漫でもあり、なんか読みづらい。序盤の数章は読んで面白かったんだけどね。karinoさんも、Brendan Greggの他の本への感想に似たようなことを書いていたので、これはこの人の方向性ということなんだろう。悪い本ではぜんぜんないというか、持っていて良い本だとは思うけれど。
並列コンピュータ &amp;ndash; 非定量的アプローチ 出身大学の天野英晴先生が書いた日本語の本。これは面白く読んだ。並列コンピュータの構成方法についての細かい話がいろいろわかりやすくまとまっている。たとえばキャッシュコヒーレンシや共有メモリモデル、クラスタマシンなどなど。まえがきによれば過去あった本の再編とのことだけど、最後にGPUなどのアクセラレータを扱った章も書き足されている。こういう分野は普段の仕事と縁遠いから、それゆえに読んでいて面白い。
なお、タイトルはヘネパタ（『コンピュータ・アーキテクチャ　定量的アプローチ』）をもじったものだけど、そんなヘネパタみたいなことは普通はできないし、複雑化したコンピュータを定量的に理解するのもだんだん難しくなってきているから……といった話がまえがきに書いてあるのがわりと面白い。これは出版社のサイトの「試し読み」から一読できるので興味があればどうぞ。
Reverse Engineering the source code of the BioNTech/Pfizer SARS-CoV-2 Vaccine そういえば年末に読んだこれはけっこう面白かった。新型コロナウィルスのワクチンの「ソースコード」を解説する記事。DNAの各パートについて、それぞれがどういう意味なのかを説明してくれている。この記事にかぎらず解説記事というのはいくつもあるものだと思うけれど、この記事はプログラマによる解説記事なのでプログラマが読んでわかりやすいたとえが入っているのが特徴。これを読んだ後にほかの解説記事を読んだら理解しやすくなったように感じた（気のせいだと思うけど）。日本語翻訳も上がっていて、そちらも良いけれどこのプログラマ向けっぽい感じが少し薄れている気がする。
 morrita 自分も BPF Performance Tools 読みました。 Systems Performance もそうですが、 この人の「持っている知識の確かさ」と「著者としてのいまいちさ」のギャップはなんなんでしょうね・・・。   </description>
    </item>
    
    <item>
      <title>Re: ハイテクしごと</title>
      <link>https://messagepassing.github.io/006-hitech/02-morrita/</link>
      <pubDate>Sun, 03 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/006-hitech/02-morrita/</guid>
      <description>大企業におけるハイテク私感 大企業下っ端なので全然ハイテクとかしてない。 ここでいうハイテクは、それなりに (CS 的な) 難しさのある、それなりの規模のコードという風に解釈している。
ある程度成熟した大企業だと、インフラ部門とかリサーチ部門とかがあってハイテクなものを専業で作っている。 なのでハイテク指向な人はそういう部門ではたらく傾向がある。
一方のアプリやサービス部門の人は、実製品開発が好きだからそういうチームにいる。 だから個人の性向としてハイテクより仕事を片付けるのを優先しがち。 それを退屈に感じたこともあったけれど、最近は締切を守ってモノを出す姿勢も大事だなと考えるようになった。 なぜならちゃんとモノが出ていくから。大企業、野心的すぎて完成する前にお蔵入りしてしまうプロジェクトもよくあるね。
専業のインフラ部門とは別に、巨大製品チームはインフラ部門やリサーチ部門相当を内部で抱えている。 たとえば YouTube は Procella というデータベースを内製しているらしい。わけがわからない。 製品内ハイテクはインフラやリサーチ発のテクノロジよりドメイン依存で、身近な面もある。 とはいえ巨大製品のハイテクは黎明期の発明の二周目三周目なことが多く、個人作品というより組織戦の色が濃い。
そんなアプリ・サービス部門でもバーンと一周目のハイテクをキメる人はたまにいて、 そういう野心がある人はだいたい出世して TL とかになる。そして二周目三周目の製品内ハイテクプロジェクトを主導していく。
つまり実勢品でハイテクをキメられるくらいならもっと出世してるっつーの！（突然の八つ当たり。） 下っ端の実力は推して知るべし。
傍から見ていると、小さいチームより成功してある程度規模のあるチームの方がハイテクの機会は多いように見える。 というのも小さいチームは技術的障壁以前に product-market fit みたいので苦戦することが多いので、 よくいえばスタートアップ的に動くものを優先しがちだから。成功して、はじめてハイテクの必要性が生まれるのではないか。 あと勢い良く伸びている製品の方が予算の融通が効く面もある気がする。やんちゃする余裕がある。
テクノロジーありきの製品も色々あるけど、 というか自分が仕事で手伝っているのもそうした製品の一つだけれど、コアテクノロジは先に書いたようなリサーチ部門や、 リサーチ部門ではないにせよリサーチ的な性格のチームとから出てくることが多い。 たとえば実験的な OS を作ってしまうチームとか。
零細企業でのハイテク 自分が零細企業勤務だった十年前のことを考えると、その会社はなぜか自社ミドルウェア用に公開鍵暗号を実装していた。 細かいことは忘れたが他にも似たレベルの再発明ハイテクがもう一つ二つあったと思う。 再発明に見合う品質やユニークさはなかったと思うが、組織の未熟さゆえにこれらのハイテクは生まれることができた。 要するに良くない判断を止める人がいなかったからやんちゃできた。こういうのは零細、中小企業だと割とよくある話だと思う。
製品の要請から意味のあるハイテクが生まれることは、小さい企業でもあるだろう。 インフラ部門やリサーチ部門がないぶん製品チームが腕まくりしてハイテクに挑む。 karino2 はきっとこのケースに近いのでしょう。
企業規模とは無関係に、ハイテク自作の文脈でオープンソースの影響は無視できないと思う。 よいニッチを見つけないとオープンソースの既存実装に勝てない。 自分で何か書くと言い張るのは、昔よりやや難しい。 オープンソースの隆盛にあわせ、世の中全体としてハイテクを自作する割合は減っているんじゃないかな。 ソフトウェア産業は拡大してるから絶対数は増えてるかもしれないけれど。
ベテランの気晴らしハイテク 権力のある古株のエンジニアが、仕事に飽きて気晴らしにハイテクをはじめてしまうことがある。 そんなハイテクは難しくて新しいことをすること自体が動機になりがちで、製品の要請に基づかないことが多い。 その一方で権力者の仕事だけに割と影響範囲もでかくなりがち。
森田は過去に何度もこの気晴らしハイテクを目撃しており、そのせいで迷惑したことも一度ではない。 そのせいかこうしたプロジェクトには強い嫌悪があり、 反動でなるべく地味に堅実な成果を出したいバイアスがある。
とはいえ退屈していたベテランが考え事をしていたら製品の隠れた要請に気づいてしまうこともあるわけで、 あるハイテクプロジェクトが製品の要請なのか単なる気晴らしなのかは、最初ははっきりしない。 自分が「それ趣味プロジェクトでしょ」と斜に構えていたらいい成果を出したベテラン発のハイテクも何度か目にしてきた。
小粒な気晴らし 自分も今のチームに異動して三年。社歴に至っては十年。だいぶ飽きている。 あーなんか気の利いたコードを書きたいなーと思いつつ地味にバグをなおして暮らしている。
が、ふとした思いつきから年末に仕事でプログラミング言語を実装した。 三日で書いて二千行みたいな超小粒言語で、仕様も大学生の宿題みたいに素朴なもの。 GC も Java まかせで、ハイテクとは程遠い。 ただ「仕事でプログラミング言語を書く」というハッタリじみた響きが気に入っている。</description>
    </item>
    
    <item>
      <title>ハイテクしごと</title>
      <link>https://messagepassing.github.io/006-hitech/01-karino2/</link>
      <pubDate>Sat, 02 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/006-hitech/01-karino2/</guid>
      <description>お仕事で計算グラフなコードを書いた 先日、仕事で計算グラフを構築して変形して実行するようなコードを書く必要があって、 そんな類のライブラリを書いて機能を実装した。コアの部分で1万行くらい。まぁまぁ大変で三ヶ月くらい掛かった。
DSLで計算グラフを構築し、 それをいろいろと操作し、最後に生成されたIRをなんらかの形で実行する。 ここ数年、こうした形で新しいものがいろいろ生まれているように思う。 古くはLINQ、より最近だとTensorFlowとかHalideとか。 あまり詳しくないが分散ビルドなどもこうした形式だとか。
そういう訳で近年この手の、実際にコードと実行の間に一旦シンボリックなグラフを置いて、 それをいろいろ操作する事で、そのまま実行するのでは得られない付加機能をつけるのは一般的になっている気はしていた。
でもそれを自分で実装するのは今回初めてで、おぉ、これが噂のあれかという気分。
ハイテクな物を実装するレア度とチャンス こういう流行りのハイテク技術を仕事で実装する機会というのはどの位レアなものだろうか？ バグを修正したり普通の機能を足すような「日常のタスク」よりはだいぶレアな気がする。 でも、ハイテクなプロダクトを売りにしていこうと思えば一つや二つは含まれる事もままある訳で、 それを実現するのが我らであることを思えばそこまでレアでも無いのでは無いか。 仕事をしていれば2〜3年に一回くらいは実装して良いような機会に出会う程度のレアさな気もする。（本当だろうか？）
一方で実装しても良い機会にあっても、別に実装せず見過ごす事も出来る。 仕事のタスクとして現れるハイテクな可能性には、だいたい迂回してもっと普通に泥臭く実装できる方法がある。 LevelDBを新しく作らずにSQLiteを使う事も出来る。 TensorFlowを実装せずにOpenMPとCUDAで手書き実装していく事だって出来る。 機会がある事と、その機会に直面した時にハイテクの実装に踏み切る事はイコールでは無い、というか見送る事も多い気はする。 踏み切るかかどうかは立場や環境にも依る。
チームの規模とか会社の規模とか 大規模チームだと、本当に一握りの中心に居るエースしかそういうのにチャレンジしない気がする。 別に末端のプログラマもガンガンチャレンジしていっても良い気もするが、あんまり見かけない。
大規模チームでは一部の人だけかもしれないが、大企業という枠ならどうだろう？ 大企業でも小さなプロジェクトの立ち上げなら割と自分でいろいろ実装する機会はあるので、 普通のプログラマでもそれなりにハイテク実装する機会もあるのかしら？「普通のプログラマ」の定義も難しい所だが。
小規模のスタートアップなら、テクノロジーを売りにするならそういうのには挑みそうな気もするが、、、挑むかな？ 口先だけではやってるとは言うだろうが、本当にやってるのがどのくらいいるかは良く分からない。 失敗するとそこで会社は終わりなので、結構勇気はいる。 今回自分が実装に踏み切る時も、頓挫したらごめんなさいねと説明した上で始めた。 気軽に失敗させてくれるのはCTOの器かもしれない。
何がハイテクなのか 完全に主観の話になりますが。
例えばコンビネータ型のライブラリを自分で作るくらいなら、目新しい応用例なら自分的には日常からはずれたハイテクの範囲に入る気がする。 でも、本質的にパーサーだが微妙にテキストじゃない、みたいな、既存のパーサーコンビネータそのまんまの用途の場合はハイテクという気もしない。 割と新しい用途にコンビネータ型の解決を見出す所にハイテク感を感じる訳だ。 余談だが、今回自分はコンビネータ型のライブラリでクールに作れる所を気づかずに手実装してしまい、後で気づいた。悔しい。 みんなはどのくらいコンビネータ型のライブラリを仕事で自作する機会ありますか？＞all
FollyのFutureを参考に自分らの環境でFuture-Promiseを実装するくらいではハイテクとは認めない。 C++だとそれなりにenable_ifとか必要だけれど。 通常のタスクの中の普通のライブラリ作成くらいだとハイテク感は感じないよなぁ。FutureをAtomicだけで実装するとかかなり大変だけどね。 大変さとハイテク感はまたちょっと違うんだろうな。かっこよさが無いとダメな気がする。 Futureにハイテク感を感じないのはいまさらに感じるからかもしれない。
なんとなくだが、自分の中ではBerkeleyDBのような物を再実装するのはハイテク枠に入っている。 再実装自体はどうという事も無いのだけど、わざわざそんな物を再実装するくらいの何かを作っているというのはハイテクな気がする。どうだろう？
仕事でハイテクな何か実装する機会とか、ハイテクとはそもそもどんなものかとか、その辺どうっすか？＞ハイテクに一家言ありそうなmorritaさん</description>
    </item>
    
    <item>
      <title>Re: 今年読んだもの</title>
      <link>https://messagepassing.github.io/004-whatiread/02-karino2/</link>
      <pubDate>Wed, 30 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/004-whatiread/02-karino2/</guid>
      <description>今年はあんまり読んでないかと思っていたが、見直してみると数は多いので代表的なのだけ。
System Performance Brendan Greggの本、これは仕事をはじめる前の無職の頃に買って読んでいた本。 森田さんが良くBrendan Greggの言及をするので自分もdtraceって奴をちゃんと勉強しておくか〜、と思って買った。能書きが多くて同じようなことを延々と繰り返してて辛い本だが、レシピ集的には素晴らしい、という二面性のある、評価の難しい本。当時の読書記録はこちら。 読書記録: System Performance
なお、パフォーマンスつながりでiOSの事情を知る為に iOS and macOS Performance Tuning: Cocoa, Cocoa Touch, Objective-C, and Swift も読んだ。 そんなに深い話では無いが、普通にiOS上で使えるツール等が書いてあってiOSの基本的な話題もあって悪くはない。 ちなみにiOSではdtraceを使えそうな事が書いてあったが、たぶん使えないのでは？でもiOSにトレーシング系のプロファイラが無いというのも信じがたい？知っている人居たら教えて下さい。
C++の本 今年はC++の本をいろいろ読んだ。
 The C++ Programming Language 4th edition Effective Modern C++  上記２冊の当時の感想 最近読んだC++の本2冊の感想   Modern C++ Programming Cookbook  この本はいまいち。当時の感想 書籍: Modern C++ Programming Cookbook    一番上のStroustrup本は業務でも日常的に（一日に数回くらい）参照するくらいには良く使ってる。 でもこの本がC++ 11までしか扱っていない、というのが、 現状のC++を学ぶ時の困った状況を表している気がする。せめてC++14に対応した版が欲しいなぁ… 上２冊は良い本だとは思うけれど、これだけでは言語をとりまく状況の複雑さを思うと、全然足りないなぁ、とも思ってしまう。 Stroustrup本は1279ページ（！）もあるのに足りないとか言われても…という気もするが。
* OS Internals iOSとOS Xのインターナルの本。何故か物理本でしか売ってない上に上記のサイトがどう買ったらいいか謎が多く、Paypalでお金を振り込んでメールをする、みたいな不安のあるフローで、HTTPSじゃないし怪しさ爆裂。でもちゃんと届いた。
期待よりもOS Xの話が多くてちょっとがっかりだが、InternalはOS Xの方がわかるんだろうねぇ。 やっぱコアの部分はAndroidの方が良く分かるので勉強し甲斐は向こうの方があるよなぁ。</description>
    </item>
    
    <item>
      <title>Re^3: テキストエディタのはなし</title>
      <link>https://messagepassing.github.io/003-editors/04-karino2/</link>
      <pubDate>Wed, 30 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/003-editors/04-karino2/</guid>
      <description>自分もjmukに似てて、VS Codeです。 以前のように自分でいじったエディタを使ったりはしてないですね。 あまり面白みは無いですが、それが何かの結論を表している気もする。
現在のエディタ環境 メインはVS Codeでエディタ作業はプログラム以外もこれでやっている。 Cloudとかターミナル上の作業ではvimも使っている。カスタマイズ無し。
また、Android開発はAndroid Studioで、iOSはXCodeで、Qt開発はQtCreatorを使っている。 これらのIDEを使っている時間もそれなりに長い。 自分はデフォルト教の熱心な信者なので、 全て基本はカスタマイズ無しのデフォルトで使っていて、 各環境に自分の方を訓練で適応させている。
RascalとIDE体験 自分は昔、xyzzy というエディタをいろいろいじったカスタム版を自分でビルドして使っていて、lispもかなり書いていた。 かなり重度のEmacs系エディタ派閥だった。
ところが2005年に Microsoft 社内向けの簡易版VSであるRascalというのを使うようになり、 これがめちゃくちゃ出来が良かった。 今振り返るとこの時がEmacs系エディタ派からIDE派に鞍替えした瞬間だったと思う。
Rascalは、外にリリースされた物ではVisual C# Express Editionに近い。 だがRascalはよりエディタ的に使えて、小さいのでインストールもすぐに終わって、 デバッガもついててリファクタリングブラウザも補完もちゃんと動いた。 テストサーバーでテストがこけた時なども、ログインしてちょろっと持ってきてデバッグに使えて良かった。 このRascalが自分的な最初の現代的なIDE体験で、 これ以降メインの環境はIDEにしようと思い、IDEの学習に多くの時間を投資するようになった。
この2005年が自分には画期だったと思う。 世の中もIntelliJが革命的な進歩を果たしたのは2004年という事になっていて、 この2004年〜2005年あたりにIDEの時代が到来したんじゃないか。
今回のトピックでもVS CodeとIntelliJ系列がほぼ全てを占めているので、 15年かけてJavaとC#以外の環境にもその２つが浸透したんじゃないか。 だが15年の間にはそれなりに回り道もあった。
それ以外のIDEとしてのVS Code Rascal以後、全てがIDEになってめでたしめでたしになるかと思っていたが、その後クラウドの時代が来ると、 スクリプトなどを書く事が増えたり設定をしてないターミナル上（EMR上のインスタンスの中とか）での作業が増えて、 vimとか原始的な環境で作業をしてた。
この辺の時代になると、自分の環境は、
 IDE上の開発 IDE以外での開発  の2つが大きく分かれた別の世界になっていた。 IDEは日々進んでいて新しい機能が入っていく。 一方でIDE以外での開発は昔から変わらぬ環境。
IDE以外の環境ももうちょっとなんとかならんかなぁ〜と思っていた所にVS Codeが登場した。 触ってみると昔のRascalっぽい。いいねっ！と一気にファンになり、 IDE以外の世界にもIDE的な物がやってきて、以後みんな幸せに暮らしましたとさ。
vimの台頭 自分は長らく Emacs 系エディタに多くの時間を投資していたが、 IDEの時代、そのあとクラウドの時代が来てみると、Emacs系のエディタは不便さが目立つようになる。 一方でvimは自分のマシンでない一時的な環境での作業やIDEの隙間のちょっとした作業にいい感じにミートして、 それ以外+vimという形で割と皆が使うようになってきた（気がする）。 自分もそうだしjmukもそうだと言っている。
vimの方がEmacsよりもむしろ現代的なのは、逆説的で面白いなぁ、と思うのだった。
 morrita 案外あっさりおわってしまった。時代ですかね。
なお読者への補足として karino2 と jmuk は一時期 VS Code のコアを使ったウェブベースのエディタを開発していた VS Code 愛ある人々です。</description>
    </item>
    
    <item>
      <title>Re: Re: テキストエディタのはなし</title>
      <link>https://messagepassing.github.io/003-editors/03-morrita/</link>
      <pubDate>Tue, 29 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/003-editors/03-morrita/</guid>
      <description>自分の状況は 向井さんと似てる。つまり Emacs は使ってない。 ただ VS Code もそんなに使ってない。VS Code は他のものがないときの fallback というかんじ。カスタマイズもしてない。 仕事が Andoid アプリなのでそこは必然的に Android Studio. 一時期サーバ側の C++ を書いていた頃は CLion に金を払っていた。 これらは今はリモートデスクトップ越しに使っている。きびしい。
Git のコミットログとかは vim だけれど、それはエディタというより Git の機能みたいな気分で使ってる。まったく使いこなしてない。 2020 になってようやくコピーアンドペーストのキーバインドを覚えた。なにこれ革命的に便利。
仕事だと他に社内の Web-based のエディタがあって、最近は Java 以外だとだいたいそれを使っている。
Web-based なエディタ その内製 Web-based エディタ、所詮は内製ツールなので VS code みたいな出来のよさには遠く及ばない。補完もなんとなくされるかな程度。 イメージとしては Jupyter Notebook/Lab くらいの編集力。ただレポジトリとくっついてるのでブラウザ上でブランチつくってコミットもとかできるし、ビルドもテストもできる。 コードレビューも出せる、のみならず、レビューコメントがエディタから見えたりもする。
あとコードは CITC という仕組みで ブラウザ上での編集がなぜか手元にも反映されるので、ブラウザでできないこと (ビルドされたアプリを adb install するとか)はローカル環境でできる。
サーバ側のプログラマにはこれだけで暮らしている人も割といる。ほんまいかなと思うけど、 いわゆる「コード」だけでなく謎の設定ファイルをいじる仕事が大量にある場合はウェブエディタでも大差ないのかもしれない。 SQL や Python みたいにどのみち IDE の強力な支援が期待できない言語にも同じことがいる。 リモートデスクトップと比べるとキータイプ単位でレイテンシが無いのも良い。不毛な比較だけれど。
Web-based なエディタが存在できる理由の一つは「ローカルの設定」を必要としない monorepo と hermetic build の力かもしれない。 エディタからのビルドは要するに CI をトリガするようなものだけれど、ビルドのたびに環境をつくったら時間がかかって仕方がないし、 状態のキャッシュとかも下手にやるとビルドの安定性を損ねる。そのへんの問題が解決済なので Web-based エディタでもなんとかなる。</description>
    </item>
    
    <item>
      <title>今年読んだもの</title>
      <link>https://messagepassing.github.io/004-whatiread/01-morrita/</link>
      <pubDate>Tue, 29 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/004-whatiread/01-morrita/</guid>
      <description>年の瀬なので振り返りもかねて今年読んだものでも紹介してみたい。 (草稿を書いたのは年末だけど、ぼんやりしてるうちに年が明けてしまった！)
といっても森田は今年は他人に勧められるほど良い読み物との出会いはなかった。 世が不作なわけではなく、パンデミックのせいで可処分時間や心の余裕がなかった。 なので他の人のおすすめに従って失われた一年をちょっとでも取り戻したい下心がある。
それでもブックマークなどを発掘したら少しはものを読んでいた（あるいは audiobook で聴いていた）ので、 その範囲で面白かったものを紹介したい。
まず書籍 3 冊。
Remote: Office Not Required Rails の開発者 DHH がつくったウェブ企業 Basecamp (当時は 37signals) がリモートワークについて書いた本。2013 年出版だが、 パンデミックの今年読むと趣深い。いいこと言ってる。7 年の月日を経てテクノロジーの問題はだいたい解決した感があるけれど、 文化的には企業間の差は大きいように思う。この本は動きの鈍い大企業に先んじてリモート化を進め差をつけろと謳う。 自分は差をつけられる側だと思うと複雑な心境。
リモート勤務、企業の個体差だけでなく我々従業員の個人差も大きいと思う。 たとえば長い通勤と引き換えに広い家を選んだ人はリモートが嬉しいだろうし、 通勤を縮めるために狭い家、高い家賃を選んだ自分のような人に嬉しさは薄い。 パンデミックはさておくと自由度の高い独身者はリモートワークの柔軟性を目一杯活かせる一方、 自分のように妻子があったり、更に子が就学していたりすると、 学校という時間的・地理的自由ゼロの活動に縛られてリモートがもたらすはずの生活の柔軟性は生かせない。
Basecamp 書籍は読むたびに我が身とくらべしょんぼりするが、そのしょんぼりが顕著な一冊だった。リモート欲を高めたい人にはおすすめ。
Facebook: The Inside Story Steven Levy による Facebook 読み物。 In the Plex や The Everything Store が好きだった人にはおすすめだし、それだけでなくゼロ年代のウェブの盛り上がりを生きてきた自分と同世代のひと（おっさん）も楽しく読めると思う。 今は色々言われている Facebook だけど、「ウェブでクールなサービスを出してゲットリッチ」というその世代の夢の頂点なのもまた事実なので。
電話機の OS を開発していた（が途中でやめた）話など、それなりに目新しいインサイダーストーリーも多い。
Google BigQuery: The Definitive Guide: Data Warehousing, Analytics, and Machine Learning at Scale 自分は仕事でよく BigQuery (の祖先の Dremel) の SQL を書いているが、いかんせん SQL 素人すぎていつも辛い。ちょっと付け焼き刃でなんとかしたいと思っても、世の SQL 入門書は OLTP 系の用途に偏っていて分析/OLAP 向けの入門に良いやつがない。しかも BigQuery/Dremel の SQL はネストしたデータがバンバンでてくるなど特殊な面も多い。助けてくれ・・・とおもってこの本を眺めたら、そういう「SQL 素人が BigQuery でやっつけ仕事をする」のに必要な SQL がちょうどよく紹介されていて救われた。ユーザ分析とかしたいけど SQL わからん・・・と腰が重いモバイル開発者におすすめ。</description>
    </item>
    
    <item>
      <title>Re: テキストエディタのはなし</title>
      <link>https://messagepassing.github.io/003-editors/02-jmuk/</link>
      <pubDate>Mon, 28 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/003-editors/02-jmuk/</guid>
      <description>エディタ、いまはもうだいたいVScodeだけでやっている。昔はEmacsだったけど、完全に脱却してしまった。もう一切使っていない。
VScodeへの移行 あれは2016年のことだったか。それとも2017年？　そのころにVScodeに移行したのだと思う。それまではずっとEmacs使いだったけれど、同時にもう何年も、いいかげんやめようと思っていたのだった。正直自分はEmacsを使いこなしていなかったし、Emacsラブということもとくにない。手に馴染むから使っていただけのことだった。それまで、たとえばIntelliJやEclipseを試したこともあったが、重さが気になったり、しっくりこなかった。社内C++業だとなかなかうまく動かないという事情もあるけれど。そういえば一瞬だけちょっとAndroidのことをやったことがあったときはIntelliJを使ったと思う。
さて、そんなわけで「もうEmacsじゃないだろう」とはずっと思っていたけれど、代替物がなかなかないなと思っていたころに、試してみるかと思って使ってみたのが当時流行っていたAtomと、出始めで勢いのあるVScodeだった。で、そのとき試してみたところVScodeのほうがちゃんと動いたのでそっちにするか、と思ってそのまま。VScode / Electronへの理解はまったく深まっていないのだが、なんとなく使えるのでそのまま使っているという、ある種堕落したような使い方をしている。凝った設定はなにもしていない。Emacsからの脱却が目的なのでキーバインド等もいじっていない。
Chromium規模のC++だと標準のモードはけっきょくあまり役に立たないのだが、さいわいChromium内で開発者向けの設定tipsが公開されているので、それをありがたく参照させていただいている。clangdを使った設定がよく動いているのでそれを利用している。OS側でのGo言語利用も、ちょっとだけGOPATH設定などをカスタマイズしているだけで、VScodeで使っている。Goland/CLionはちょっと興味あるけど、使ったことはないなあ。
リモートワークとエディタ環境 さて、2020年になって大部分の時間をリモートワークとして自宅から仕事するようになった。自分の場合、開発用のワークステーションは会社内に置きっぱなしのままで、手元の環境はChromebookだけという状態で仕事をしている。そうすると、sshだけで作業を完結させたくて、コンソール内で動作するテキストエディタに利点が出てきた、ように思える。2020年リモートワークの時代から、コンソールエディタの復権があったりするだろうか？
などと妄想するものの、自分の場合はそうなっていない。実は自分は会社に出勤して仕事してたときから、ずっと手元の操作環境はChromeOSにしていて、開発用ワークステーションへはリモートアクセスしていた。VScodeはリモートデスクトップで接続してそこから使うかたちにしている。リモートデスクトップだとレイテンシが気になるところだと思うのだけど、社内で仕事をしているかぎりはストレスを感じることはほぼなかった。これが自宅からだとどうなるか……と戦々恐々だったが、おもいのほかなんとかなっているので、そのままvscode on remote desktopというスタイルで仕事を続けている。
みんなどうしているんだろうか。自分のごく狭い範囲を観測するかぎり、リモートデスクトップは極端なパターンで、たいていの人はローカルに開発環境を持っていて、そこで開発をしているような気がする。やっぱりコンソールエディタの復権ということはないかな。それに復権するべきコンソールエディタというものの選択肢があまりにもないわけですが。
リモートワーク開発環境どうでしょう。&amp;gt; morrita
 vim ところで今年は Advent of Code を完走してみたのだが、Go言語を使い、コーディングにはおもにvimを使った。手元のChromebookのLinux環境を使っていたので、あんまりヘビーウェイトなもので書きたくない、というわけでvim。gvim使ったりしたけど途中でふつうのvimに移行してしまった。vimのGo言語プラグインはわりとよくできていて不満がない。
ところで、仕事ではだいたいVSCodeだと書いたけど、ちょっとしたことにはやっぱりvimを使っている（なんせgit commitしたらvimでコミットメッセージを書いている）。Emacsからは脱却できたけど、vimを完全に追い出すことはできていない。やっぱりコンソールエディタなのか……というのはふざけているにすぎないが、vimはどこででも動くし役に立つ。でも正直なところ、vimにはいまさらbetしたくないし、凝った設定も入れたくはない。ちょっとしたことを書くのに使うのみにとどめていたい。</description>
    </item>
    
    <item>
      <title>テキストエディタのはなし</title>
      <link>https://messagepassing.github.io/003-editors/01-kzys/</link>
      <pubDate>Sat, 26 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/003-editors/01-kzys/</guid>
      <description>morrita 我々みな Emacs 世代だと思うけど、最近つかってるエディタなんかあります？ (内輪のスレッドより引用)   GoLand 仕事で IntelliJ を使っていたこともあって、仕事の Go は GoLand で書いている。定義元に飛ぶとか、シンボルのリネームとか、IDE っぽい機能が一通り動いて便利。
IDE を使うのは Emacs に無い機能が嬉しいからで、つまり Emacs のキーボードショートカットと IDE のそれは一対一対応にならないので、それなら IDE のキーボードショートカットをちゃんと覚えたほうがいいのでは、と思っているけれど、結局カーソルを動かすとかは Emacs の C-f/n/b/p に慣れすぎていて変えられず、デフォルトのものをちょっとだけ Emacs 風にしている。
Visual Studio Code 自分のブログの Markdown とか、IDE を使わないときは Visual Studio Code を使うことが多い。Visual Studio Code の Emacs 風の拡張はたくさんあるけれど、私は作者の VSCodeのキーバインド拡張を作ったので、その勘所を紹介 に説得 (?) されて、Awesome Emacs Keymap を使っている。
Remote Development が結構よかったのと、edamagit という Magit クローンが気になっていて、この二つをちゃんと自分が使えるようになったら、Emacs 使わなくても良くなるかもしれない。
Emacs でも Emacs もまだ使っている。用途は、Magit:ファイル1枚くらいで完結するスクリプト:複数のプロジェクトを行き来する必要があるとき = 8:1:1 くらいで、昔に比べるとだいぶ減った。
これをここからゼロにするかというと、うーん、どうなんだろう。私は Linux 使いはじめるまえに Meadow (というのは Windows で動く Emacs の一種です) を使っていたりして、Emacs とか Unix っぽいツール群がスッと動くことが Linux 使い出したときの感動のひとつだったりしたので、結構 Emacs 愛があるような気がする。</description>
    </item>
    
    <item>
      <title>Re: Re: Re: 言語のはなし</title>
      <link>https://messagepassing.github.io/002-pl/04-morrita/</link>
      <pubDate>Tue, 22 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/002-pl/04-morrita/</guid>
      <description>F# を日用する karino2, Scala にパッチを書いていた kzys, Haskell の本を書いてしまった jmuk のあとに 日々 for 文を書いて暮らしている自分になにか言うことがあるのか疑問だが、賑やかし程度になんか書く。
Arrow まず冒頭に出てきた F# の bind に相当するのは Kotlin には無いという話。 Kotlin には Arrow という FP 愛好家向けのマイナーライブラリがある。 そして Kotlin には coroutine がある。その二つは一緒に使われて Monad Comprehension という機能になっている。（らしい。）これがどのくらい F# の bind に近いのか自分はよくわからないけれど、そういうのが好きな人はいることはわかる。
一方で、仮にこれがまあまあ monad してるとしても、こうした流儀が Kotlin コミュニティの中心にあるとは思えない。 端的にいうと Android プログラマは(近似的には)誰も仕事で Arrow 使ってないよね。 同じ JVM 言語でも、Scala なら scalaz なり cats なりは もうちょっと受け入れられているように外野からは見える。 (なお森田の Scala FP 力はこの本 を途中で投げ出したくらい。つまり雑魚。あまり真に受けないでいただきたく。) F# は、よくしらないけどたぶんもうちょっと Haskell に近く functional first なのではなかろうか。</description>
    </item>
    
    <item>
      <title>Re: Re: 言語のはなし</title>
      <link>https://messagepassing.github.io/002-pl/03-kzys/</link>
      <pubDate>Mon, 21 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/002-pl/03-kzys/</guid>
      <description>私はむかし Scala が好きだったので、あんまり流行らなかったのは残念です。いや、Scala 3 が Developer Preview に入る年の瀬に過去形で語るのもよくないけれど。
ランタイムが同じ言語を売り込むのは難しい C# と F#, Java と Scala みたいなランタイムが同じ言語は、既存のライブラリなどを使えるという利点はあるけれど、客観的な性能指標とかで明確に「勝つ」ことはなくて、チーム全員を説得するのが大変だと最近は思う。
ファイル一つをコピーすれば動くような実行ファイルを作りたければ Go で、メモリ安全性は手放したくないけれど、ガベージコレクションや大きいランタイムに起因する色々が嫌なら Rust で、みたいな分かりやすさに比べると、F# や Scala の良さって、言語のセマンティクスやシンタックスの話になりがちで、ちょっと弱い。
変数に再代入しない、という当たり前のことを表現するのに final って5文字も書かなくていいんですよ! ていうか Java の Collections.unmodifiableMap() って型に mutable なメソッドが生えてて実行時例外投げるってなんなの? 型に対する冒涜じゃないの? といっても、それがどのくらい許容できるかって人によってだいぶ差があって、我慢できるたぐいの良し悪しと、プログラミング言語に起因するトラブルを抱えるリスクを天秤にかけて、よし今回はこの言語でやってみよう、となることはなかなかない。10年以上プログラマをしているけど、チームの言語を切り替えられた経験って、そういえば一度もないような気がする。
その点でいうと、TypeScript は「型があるんですよ」というのが分かりやすくていい。Kotlin はどうなんだろう。
Scala のキラーアプリは Spark だったのか? Scala に関していうと、Scala が流行り出した頃は、アクターシステムの Akka とか、Rails みたいなフルスタックフレームワークの Lift や Play がキラーアプリになるかと思っていたんだけど、蓋をあけてみると、キラーアプリは Spark だったのかと思う。新しい言語には新しい問題が必要なのかもしれない。
ライブラリってどのくらいあればいいの? あと、ここ10年くらいに出てきた、Node.js (2009-), Go (2009-), Rust (2010-) がそれぞれそれなりの規模のライブラリ群を備えているのをみると、まあ10年くらいはかかっているけど、既存の言語の資産を引き継がなくてもなんとかなるんじゃないか、とも思う。
 karino ランタイムが同じ言語を売り出すのが難しいというのは、まさにC#からF#に乗り換える人はいないというのと同じ話に思う。
F#が面白かったのは、C#から乗り換える人は居なかったのだけどOCamlとかから乗り換える人が居た所だと思うんだよね。 自分もKotlinみたいに使えるコマンドライン言語がほしかったのであって、C#の代替とかCLR上の良い言語を探していた訳じゃない。Golangみたいに使えるKotlinを探していた。 これはF#使っている人が MS MVPとかじゃなくて全然別の、Unix上とかで普段生きている人でGCPやAWS使ってる人になっているところにも現れているんじゃないか。 会社の主流でない事をやっていたら会社には関心の無い他人が寄ってきた、みたいな。</description>
    </item>
    
    <item>
      <title>Re: 言語のはなし</title>
      <link>https://messagepassing.github.io/002-pl/02-jmuk/</link>
      <pubDate>Sun, 20 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/002-pl/02-jmuk/</guid>
      <description>話をふられてなんなんだけど、最近あんまりML系の言語を使ってみたりしていないんだよな。最後になにかやったのは、min-camlがwasmを吐けるようにしたことで、あれはOCamlで書いたのだったか（min-camlはセルフホストではなく、OCamlで書かれている）。公開もしていない……自分で書いた部分がかなりmessyで気が滅入る感じになってしまったので放置している。
Haskellの型クラス そういえばポッドキャストで最近、Haskellの歴史の論文を読んだのを紹介した。2カラムで50ページ以上という長大なる論文なので仕方なくかなりの部分を割愛したが、なかでも型クラスの話はほとんど触れずに飛ばしたように思う。ところがあの論文は &amp;ldquo;being lazy with class&amp;rdquo; という副題がついてるくらい、なにかと型クラスの話をする論文なのだった。論文著者の気持ちとしては、型クラスこそがHaskellの最大の発明であり、特徴であるという気持ちなのかもしれない。
これはポッドキャストでは言及したとおもうが、そもそも型クラスというのは、もともとは数値型と演算子をどうするか、というのが発端だったようだ。プログラミング言語ではたいてい整数型と浮動小数点型があり、+とかみたいな演算子を2引数の関数とみなしたとき、その型が問題になる。たとえば let add x y = x + y のような関数の型はどうあるべきなのか。この解決策として「数値という型クラス」が導入され、型クラスの仕様をみたせばどんな型でもよいことがキレイに表現できる。やったぜ。
しかしこれ、比較的どうでもよい問題について大げさなツールで解決した感は否めない。ほとんどの言語は数値型は特別扱いして、それで大きな問題は起きていない。複数の型を受け入れるためのジェネリクスはよさそうだけど、型クラスというものはなんだか大げさにも思える。
面白いのは、Haskellはこの素朴な型クラスの成功を受けて、それを発展・深化させていったところだった。たとえばモナドができたときも、モナドってつまり型クラスだよね、という話になった。ところが既存の素朴な型クラスの話とモナドは、実はうまくマッチしない。たとえばIntがNumですよ、というのとIOがMonadですよ、というのは話が違う。IOは処理結果を返す型コンストラクタにすぎないから（StringがやってくるIO Stringとか、意味のある値のないIO ()とかが、個別具体的な型になる）。だから、型クラスを拡張して、型コンストラクタも指定できるようにした。さらに、型コンストラクタが複数の型パラメータをもつとき、その型パラメータ間の関係にどんな制約をつけられるだろうか、みたいな方向性にも発展した。
こうやって、型クラスという基礎から始まり、いろいろ複雑な論理関係を表現できるようになった。型クラスというのは出発点の動機は素朴でわりとどうでもいいものだったが、その先にはいろんな発展が見込まれる、豊かな領域の基礎になるものだった（数学者みたいな物言いだけど）。そのことがHaskellまわりの人達を魅了してきたのだろう。
言語のよさと、エコシステムのよさ 話は少しそれるが、あるプログラミング言語のよさみたいなものがあるとして、それってエコシステムに大いに影響されるものだよな、などとこのごろは強く思う。昔はそうでもなかったから、これは自分の年齢が関係するんだろうな。はー歳はとりたくないものだ。でもこれが間違っているというふうにも思いづらい。
エコシステムというのは周辺ツール、ライブラリなどの話であり、言語仕様そのものとは直接的な関係はないといってもいい。どちらかといえば、人がどれだけたくさん寄り付いたかとか、サポートしてくれる企業がどれだけいたか、といった話にもなりがち。でもエコシステムってやっぱり大事なんじゃないか。エコシステムの発達は新しいニーズを生み、それが言語仕様を豊かにしていくという面もある。直接的な関係がないからといって、無関係というわけではない。
Haskellにエコシステムがない……というつもりはない。そんなことを言うと多方面から怒られそう。十分に実用されているとすらいえる。でも他の人気の言語よりはエコシステムはどうしたって薄いだろう。Haskellみたいな言語の型システムは、長年研究者たちを魅了してきたし、それによって豊かに発達したわけだが、でもたとえばtypescriptが急激に発達していろいろわけのわからない型表現を生み出し取り入れているのを眺めるに、エコシステムの発達が生み出す言語仕様の発展ということについても思い馳せるところがないでもない。
F#なんだか面白そうだな、よさそうだな、という感じも、.NETというエコシステムの上によって立つところがあるんじゃないか、というふうに思う。そしてたぶん、その基盤ゆえに独自に発達した言語仕様とかもあるんじゃないかな。そうだとすると面白いな。……と思う一方、いろいろあるJVM系言語については自分は懐疑的な視点を崩せてない（Kotlinはよさそうですけどね）。自分のJava系の経験のうすさゆえだろうか。どうですかね＞和良さんとか？</description>
    </item>
    
    <item>
      <title>Re: Re: バグのはなし</title>
      <link>https://messagepassing.github.io/001-bug/04-karino2/</link>
      <pubDate>Sat, 19 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/001-bug/04-karino2/</guid>
      <description>ここまでのかっこいいバグの話を見て、少し考えてみたが、自分の場合は10年以上前のものが多い。 最近はあんまりそういうバグが無いのだが、なんでかと考えてみる。
 長く使われるコードを書いていない 多くのユーザーに使われるコードを書いていない  という事かなぁ、と思った。
機械学習のバグ 自分のバグでかっこいいのが少ない事の一つに、機械学習の仕事が多かったからというのはあると思う。
例えば機械学習のモデルで変な推論をするみたいな話はまぁあるのだけれど、そういうのが二人のようなかっこいい感じのバグの話にならないのは、 結局そのモデルは早ければ一週間、遅くても開発が続いていれば一ヶ月後には更新されてしまうから。 すぐに更新されちゃうとバグの重みは軽い。というか機械学習のモデルの変な挙動の重みが軽くなるようにみんな体制を作っている。 特にディープなモデルは良く分からん挙動をする事があるからね。
デプロイしたモデルが動いてませんでしたみたいな事はたまにあるし、それは結構な機会損失を生んでたりもするけれど、 revertして直したのを数日後にリリースするだけなのであんまり面白みが無い。
短期のフリーランス的な立ち位置 自分の仕事は短期のフリーランスなので、エンドユーザーになにかデプロイするよりも社内向けのツールとかの仕事が多かったというのもある。 ハードウェアのテストのコードとかは、ハードウェア自身のバグに比べると面白みが無い。 ハードウェアは何億円とか掛けて工場で作って完全に使えない物が出来てしまう事もあるので、結構大ダメージではある。 なのでそういうバグは見てる分には面白かったが、 自分のバグでは無いのであんまりここに書く感じでも無い。
でもフリーランスだから雑用的な仕事が多いのか？というと…どうだろう？そうだとも、そうでないとも言える。 どちらに答えてもやや違和感が残る。
自分の印象としては、働いていた時の他のチームメンバと自分の仕事を比較して、そんなに雑用的な仕事が多かったことも無く、 むしろ短期の手伝いなので重要な仕事をする事の方が多かった。そのチーム内で見た時は正規雇用の社員に比べて雑用をしていた気はしない。
だけれど、そもそも短期のフリーランスを使うチームだという時点で、ある程度の実験的なプロジェクトとかなにかのプロジェクトの立ち上げのところとかが多く、 長く開発が続いているプロジェクトで、バグなどがバグトラッキングシステムで管理されて、それを日々直しつつ開発を続けていく、 みたいな体制のチームでは無い事が多い。 そういう仕事こそが重要な仕事であると思うなら、フリーランスは重要でない仕事が多いといえるかもしれない。
ただ自分はまぁそういうのはもういいかなぁという思いもあるので、フリーランスのお仕事は性にあってる。
会社の主流でない良さ 最近F#が雑用言語としてすごくいいなぁと思っている。 F#がいいと思う事の理由の一つに、Microsoftが力を入れて推し進めているわけ「では無い」ところがある。
C#はMicrosoftの現在の方針を色濃く反映してしまうので、クラウドに力を入れていればクラウドに、 モバイルのクロスプラットフォーム開発に力を入れていればモバイルのクラスプラットフォームに引きづられていろいろと変わっていく。 そうした方針がいつも正しく、よりよい方向に進むとは限らない。特に会社が苦戦している時には。 最近のMicrosoftのモバイル戦略なんかに合わされたらたまったものでは無い（最近の戦略なんて知りもしないで適当な事を言っているが）。
一方F#はそんなに会社の方針に合わせている感じは無く、自由にやらせている雰囲気だ。 VS CodeよりVSを優先しなきゃいけない理由も無くて、中の人も普通にVS Codeの環境をプッシュ出来る。 だからMacで開発する時も普通にVS Codeで快適に開発出来る。 Microsoftが迷走していてもあまり関係無いたたずまいに、ある種の安心感をおぼえる。 でもC#向けにいろいろ入れてくれるクラウド向けのコードなどはありがたく使わせてもらえる。 おいしくタダ乗りさせてもらっている感じが良い。
F#の良さの一つには、こうしたMicrosoftの方針の主流から外れている点があると思う。
外れているせいでC#に比べるとずっと人は掛かっていないと思うが、でも技術的につまらない事をやっている訳では無い。 むしろクロスプラットフォームでML的な関数型言語で大企業にバックアップされた豊富なライブラリというこれまでに無い価値を提供しており、 自分のようにC#よりも価値を見出している人は、Microsoftエコシステムの外にはそれなりに居る気がする。
大本営の方針に従ってやっていく方が価値があるとは限らない。この側面は、ソフトウェア業界にはあるんじゃないかね。 たくさん予算をかけて、凄いたくさんの人で壮大な計画でやった物は失敗する方が多い。 暇な時にちょっと始めた事が大きく広がる事はちょこちょこある。
大多数はどちらも大成功を生み出せないのが結論ではあるので、大本営の方針に従って粛々と働くのがダメって訳じゃない。 でもそういうのから外れた所で小粋にやっていくのもそれなりに意義のある事を生み出せるんじゃないかという気が最近していて、 その辺が「フリーランスの仕事はより雑用的で意義がない」と言う事に違和感を覚える理由にもなっている気がする。
ただフリーランスの仕事には継続的なプレッシャーにさらされる事はあまり無い。 そうした物に耐えてしかなせない事もあるとは思っているので、やっている人たちには敬意を持って接したいとは思うけれど。
という事でF#良いよという話に続く訳だが… 長くなったのでここまででこの話は一旦終えて、F#の話は次回（？）に回す事に。</description>
    </item>
    
    <item>
      <title>言語のはなし</title>
      <link>https://messagepassing.github.io/002-pl/01-karino2/</link>
      <pubDate>Sat, 19 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/002-pl/01-karino2/</guid>
      <description>F#とかML系言語の話 最近どこでもF#いいよしか言ってない気もするけれど、なかなかいいですよ、F#。 Microsoftエコシステムの外の人間の方が使いみちが多いというのが面白いところに思う。 Windows使ってる人じゃなくてMacとかLinux上でコマンドラインでなにかやりたい人にマッチしているのが盲点になりがち。 自分がまさにその盲点にはまってたんですが。
MacとかUnixでも動いて、ファイルのmoveとかcopyとかのシステム周りが一通り揃っていて、 新しい圧縮だとか通信だとかにもちゃんと大企業が対応してくれて（.NETがだけど）、 VSCodeのextentionも良く出来ていて、なおかつML系言語。 Unix系コンソールでのML系言語の時代来たな！
とか思っていたら、和良さんに DarkもOcamlからF#の時代ですよ！ とか教えてもらって、 リンク先を読んでたらReasonML とか Elm を知る。 以前AltJSとしてどっかで見かけた事はあった気がするが、 その時は好きものがやってるだけのマイナープロジェクトくらいに思っていたけれど、 F#もそんな風に思っていたのに使ってみると意外と使える感じだった。 こいつらも結構いいんじゃないか？とか思い始める。
この辺のAltJS系、それなりに流行ってるんですかね？ 自分が知らなかっただけで意外とML系言語の時代来ていた？
F#が普通のプログラマにどのくらい受け入れられるか的な話 流行るといえばどの位一般のプログラマに受けいられるのかが課題。という事で言語的な学習のしやすさを。
F#（というかML）は、表面上はPythonとかとそんなに変わらなくて、見様見真似でもちょっとは書ける。 一方で、いい感じにF#の良さを活かそうとすると、これまでのスタイルとは大きく変えてプログラミングをしないといけない。 例えばF#のパイプ演算子をうまく使うためには関数はカリー化したものを基本としてプログラムしてる方が良くて、 そうするとクラスやオブジェクトでは無くValueを基本にプログラミングをしないといけない。
このプログラムの構成の仕方の変更はそれなりに難しさ、関数型言語の素養を必要とす。 入り口は普通のプログラム言語っぽくても、結局は関数型言語として接する必要はある。 この「関数型言語としてのプログラム構成の仕方を学んで従う」のは、どのくらい普通のプログラマに受け入れられるのか？
あと、F#は割と基本的な所でモナドが出てくる。Option型を扱うのにDSLを作るのが推奨されてるっぽい感じ。 専用の構文があればいいはずなのにそういうのは無くて、 computation expressionというbind系の関数を幾つか実装すると使えるDSLを作る枠組みがあって、それを勧られる。 それにしたって最初からOption用のcomputation expressionで使えるビルダを用意しておいてくれれば、理解しなくてもしばらくは使えると思うのだが、 F#には何故かビルドインではOption用のcomputation expressionのビルダが無いので自分で書かないといけない（6行くらいで書けるけど）。
自分で書くためにはbindってなんだよ、というのを学ぶ必要があり、これはお決まりのモナド入門をやらないといけない。 提供してくれているのを使うだけならもうちょっと後回しに出来るのだけど、 提供してくれてないので言語の入門の割と初期でどうしてもbindの話が出てきてしまう。
教育的配慮もあってそうなってるのかもしれないが、 大多数の人には不要な壁になってしまっている。 F#を使う時の期待値として関数型言語の勉強という側面も持っている気がするので、 初期にbindの必要性に当たるのは悪いとも言い切れないのだけれど。
そもそもbindのシンタックスシュガーってどうなのか？ Bindって今どきのプログラマはどこかでは乗り越え済みなんですかね？
C#はLINQが入った時にみんな頑張ったし、F#も.NET勢なので.NET界隈はなぜかこの辺を普通のプログラマもやる、 という良く分からん風習があった。 でもふと冷静になって外の世界を見渡すと、なんだかんだでモバイルの2大主流言語であるKotlinにもSwiftにもない。 機械学習で主流のPythonにも、Webのフロントエンドで使うJSにもない。
パーサーコンビネータはみんな使ってると思うのだけど、別にbindとか知らんでも使える。
こうして考えると、普通にプログラム言語を使っているとbindのシンタックスシュガーのある言語を触る機会は今でも意外と無さそう。
そもそもF#で初期にbindの例で出てくるOption、先程も言ったとおりちゃんと専用のシンタックスシュガーを導入すればbindのシンタックスシュガーなんて要らないんですよね。 実際KotlinはOption(Nullable)周りに専用のシンタックスシュガーがいろいろ入っていて、 bindのシンタックスシュガーなんて無くてもむしろF#より快適に書ける。
Computation expressionの枠組みでいろいろな物を汎用的に美しく書けるとは言っても、良く出てくるケースはだいたい決まってて、 それ独自のシンタックスシュガーを入れれば特に問題は無い。 Asyncとawaitもcomputation expressionで美しく書けます、と言われても、別にsuspend関数で問題が無い。 専用の構文を入れるのはダサいかもしれないけれど、どうせ似たような仕組みに落ち着くのだから使う側的に違いは無い。 理論的に美しくないだけで学習コストを大きく下げられるのだから、そっちの方が良いのでは？という気もする。
Computation expressionは新たにDSLを作りたい時には強力な仕組みとなる訳だけど、 if elseのショートカットとかをちゃんと実現しようとすれば遅延評価みたいな仕組みも必要になってきて（F#ではDelayというのでこれを行う）、 そんなにシンプルで美しいという訳でも無い。 でもそうしたフルな機能が要らないなら別にKotlinのようにインライン周りの工夫が入っているだけで十分だったりする。 むしろreturn周りなんかはKotlinの方がシンプルに書ける事も多い。</description>
    </item>
    
    <item>
      <title>Re: Re: バグのはなし</title>
      <link>https://messagepassing.github.io/001-bug/03-jmuk/</link>
      <pubDate>Fri, 18 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/001-bug/03-jmuk/</guid>
      <description>あんまりかっこいいバグというわけでもないが、解決が楽しかったのでここに書いて供養しておこう。
最近はOSの性能テストをよく書いて計測している。Go言語で書いたテストコードがコンパイルされた上で実機上で動いてOSをいろいろ操作させるというものだが、こういうend-to-endなテストの性質上、壊れることもよくある。ある日のテストの失敗レポートもそういうよくあるやつに見えた。
ログを見ると、なかなか失敗しなさそうなところでタイムアウトして失敗している。理由もよくわからない。手元で再現させてみるが、もちろん再現しない。ところがCIでは頻繁に失敗している。なぜだろう？　考えられるのは、同じ試行で走っている前のテストケースの影響だ。それで思いつく関係しそうなテストケースをいろいろ組み合わせてみるが、それでも再現しない。
もうちょっと良く見てみよう、と失敗したログを見てみる。失敗した場合、psのダンプも保存してくれるので、それも見てみる。すると……実機上のテストコード自体のCPU負荷が300%を越えてる！！　これなのは間違いない。テストコードが狂っていてCPU負荷が高くなりすぎてOSがまともに動作できず、普段なら失敗しないところでもタイムアウトしてしまうというわけだ。
しかし何が原因なのか、どこにCPUを使っているのかは謎のままだった。仕方ないので、同じ試行で走るべき全テストを実行させつつtopでCPU使用率を目で追ってみた。するとテストの早い段階でとあるテストケースが失敗すると、その後のCPU使用率が100%を越えることがわかった。これだろう。CPU利用率は違うが、同じ問題を引き起こすテストケースがほかにいくつかあるのだろう。
問題の分析 再現環境が手に入ったので話はずいぶん簡単になったが、まだ何故これが起きたのかはわかっていない。Go言語にはプロファイラが標準で入っているから、これを使ってみることにする。自分のテストのほうでプロファイラを取るようにし、問題を起こすテストケースと自分のテストケースの2つだけを実行させる。で、これをflame graphで眺めてみたら問題は一目瞭然。cdpというライブラリのなかの、とあるgoroutineが大幅にCPUサイクルを消費している。しかもその消費の大部分は文字列フォーマットとエラーオブジェクトの構築。ようするに、エラーの報告しまくっているということだ。
cdpというのはChrome devtools protocolの略だ。OSやブラウザをテストから操作するためにこのプロトコルを使っていて、cdpというのはこれをGoから使えるようにしているサードパーティのライブラリだったが、どうもここにバグがあるらしい。それで調べてみると、たしかに問題の起きたOSバージョンから、cdpのバージョンを上げる変更が入っている。手元でcdpのバージョンを落としてみると問題が直る。
というわけでcdpのバージョンを戻せば解決するが、それじゃ本質的な解決にはならないので、もうすこしcdpの中身を眺めてみる。すると、このgoroutineは実際にchromeとのメッセージをやりとりするようなものだった。何らかの理由で通信チャネルが閉じたらエラーになるが、エラーといってもいろいろなので「エラーが起きたらエラーオブジェクトを作って報告する。もしそれがcloseに関係するエラーだったらgoroutineを終了する」といったロジックになっていた。どうも、問題の事例では本当は通信チャネルが閉じたのに、closeエラーかどうかの判定が間違っていたためgoroutineが止まらず、ビジーループでエラーオブジェクトを作り続ける無限ループに陥っていたようだ。
実際に起きているエラーがなんなのか見る方法はないだろうか？　テストは実機で走っているので、ログは簡単には仕込めない。テストインフラ側には専用のロガーがあるが、依存先であるサードパーティライブラリはそのロガーのことを知らない……。ただcdpはエラーをGoのchannelに書き出してくれていたので、テストシナリオの側でこのchannelを読んでテストインフラのロガーに流すコードを仕込んでみた。すると、たしかにエラーオブジェクトが無数に流れてくる。根本的には、cdpライブラリがさらに依存しているwebsocketライブラリのcloseエラーになっているが、手前がcdpのcloseエラーになっていないので、判定に失敗しているようだ。
解決 いったん手元では雑なパッチで修正し、問題としてはひとまず解決した。これをupstreamすることにしたのだが、そこでもうすこし問題の詳細を眺めてみた。
さっきも書いたように、いちばん根底のエラーはwebsocketライブラリのエラーだった。一番手前のエラーは全然別のエラーだ。Go言語では、こういうふうにエラーオブジェクトをベースにしてちょっとエラーメッセージを追記するようなwrapがよく行われている。cdpライブラリの場合、Causeという独自のメソッドがあり、wrappingを剥がして元のエラーオブジェクトを取れるようになっている。
ライブラリとしての構造が複雑になってくると、こういうwrappingは多段化しがちだ。実際このケースでもそうで、複数段のwrappingが入っていた。ところが問題の無限ループでは、一番手前のエラーオブジェクトと、一番奥のエラーオブジェクト（websocketライブラリのエラーオブジェクト）しかチェックしていない。実際にはcdpライブラリのcloseエラーは正しく存在していたが、この多段wrappingの中間にしかなかったので、無視される状態になっていた。そこで、このwrappingを一段ずつはがしてチェックするように修正をつくってupstreamした。これがマージされたのでこの問題はおしまい。
ところで、ちょっと勘のいいGoプログラマは気づいたかもしれないが、これはGo 1.13で導入されたerrors.Isと類似性がある( https://blog.golang.org/go1.13-errors )。Go 1.13ではerrors.Isという関数ができて、こういう「ほかのエラーオブジェクトをラップしたエラーオブジェクトとの一致チェック」というパターンを簡単にかけるようになった。errors.Isでは、エラーオブジェクトにUnwrapというメソッドがないかチェックする。あるならそれを使ってwrapを外す。どこかでtargetと一致するエラーがあったらtrueを返す。どこにもなくunwrapできなくなったらfalse。
ただ、cdpライブラリの状況ではこれはそのまま使えるものではない（とくに==でのチェックだと厳しい）。使えるようにするにしてもかなりの再設計が必要になるだろう。でもまあよくあるパターンとして比較的最近、標準でサポートされるような問題ではあるという話だったのは興味深かった。
 最後は karino2.</description>
    </item>
    
    <item>
      <title>Re: バグのはなし</title>
      <link>https://messagepassing.github.io/001-bug/02-kzys/</link>
      <pubDate>Wed, 16 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/001-bug/02-kzys/</guid>
      <description>他人にバグ修正を頼むのはよくないという反省から、このあと森田は OS ツリーのビルド、インストール方法を調べ 手元で OS のコードをいじれるようにしたのだった。ただしその成果を発揮する日は今の所きていない。来なくていいです
サーバサイドのかっこいいバグの話なんかないですか &amp;gt; 和良
 よくないまでいうと語弊があるけれど、自分で直したほうが楽ですよね。そうして軽い気持ちで手を出すと大事になったりするんですが&amp;hellip;。
というわけで、1行変更するだけのつもりが大事になった話をひとつ。
seccomp Firecracker では Linux の seccomp という仕組みを使って、Firecracker プロセスが呼び出せるシステムコールについて許可リストをもっている。Firecracker のなかで動くゲストの Linux は様々なシステムコールを自由に発行できるけれど、Firecracker プロセスがホストの Linux に対して呼び出すシステムコールは厳選されている。
実際の許可リストは、src/vmm/src/default_syscalls/filters.rs にある。この仕組みは、本来なら libc やライブラリが隠蔽してくるはずの実装の詳細であるシステムコールを細かく列挙しなくてはいけないので、結構きびしい。
このとき直したかったバグでは
 After more digging, looks like the rt_sigprocmask is unescapable. It&amp;rsquo;s also called from __block_all_sigs, which is in turn called by pthread_exit. Basically musl took every precaution and blocks signals whenever something signal-unsafe is underway.
 Firecracker がスレッドを終了すると、musl libc 経由で pthread_exit が呼ばれて、そこから rt_sigprocmask というシステムコールが呼ばれてしまうので、結果として seccomp 違反で Firecracker が殺されてしまう、という話だった。</description>
    </item>
    
    <item>
      <title>バグのはなし</title>
      <link>https://messagepassing.github.io/001-bug/01-morrita/</link>
      <pubDate>Mon, 14 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://messagepassing.github.io/001-bug/01-morrita/</guid>
      <description>なにか話すことはないかと Hacker News をみていたら（ろくでもない）、 Youtube や Gmail など Google のサービスが一時間落ちていたというニュースで 盛り上がっていた。担当者の想像するだけで胃が痛い。
森田はクライアントサイドで仕事をしているので、この手の outage は起きない。 けれど自分のところに担当したくないイヤなバグが回ってくることはたまにある。 そういうのを精神衛生を害さない程度で思い出してみたい。
A Ship Blocker 何年か前にカメラアプリのチームに入った直後、ハカソンでカメラのビューファインダに OpenGL のシェーダで簡単なエフェクトをかけるコードを書いた。
ハカソン最終日のデモで成果を紹介すると、より洗練されたリアルタイムエフェクトを近隣のアルゴリズムチームが長いこと構想していたことがわかった。 そこで彼らが開発していたエフェクトのフレームワークを森田がカメラアプリにインテグレートすることになった。 とはいえアルゴリズムの開発は始まったばかりで出荷するのはまだ先になりそうな雰囲気。 アルゴリズムチームがアプリ内で試行錯誤できるよう、早速ハカソンのコードをベースに最低限のインテグレーションを済ませた。
その仕事のことをすっかり忘れていたある日、アルゴリズムチームの人が「そろそろ出荷に向けて準備したいのでバグなおしてくれない？」とやってきた。 改めて自分のインテグレーションを見直すと・・・バグだらけじゃん。特に電話機の向きを縦から横にかえた時に描画が壊れる。 やれやれ・・・と直そうとするも、API が期待通りに動かない。
一週間以上たってもなぜ動かないのかわからないので途方にくれ、 小さな再現ケースをつくって、 正しくうごくケースすなわちエフェクトなしのコードパスと挙動を比べてみると・・・。
これ OS のバグじゃね？という結論に至った。 一般に OS のバグを疑うときは自分が間違っているものだが、Android に限るとその限りでない。 先に書いた再現ケースを片手にバグ報告をする。
が、まったく相手にされる様子がない。 しびれを切らしたアルゴリズムチームのプログラマがやってきた。「担当者に直談判しましょう」という。 仕方ないので質問ドキュメントを事前に送付の上ミーティング。「ああわかったきがする。すぐ直すよ」と担当者。
しかしコードがチェックインされたのはそこから一ヶ月後だった。しかも直ってない！どうなってんた！ アルゴリズムチームにつつかれ、ふたたびミーティング。前回は問題だけ伝えたのがよくなかっという反省から、 もう少し要求を細かく伝える。このあとようやく修正が通り、デモが動くようになった。
しかし OS のバグはトランクでのみ修正されており、気がつくとリリースブランチはとっくの昔に切られていた。 そして cherry-pick の締切も過ぎていた。この OS のバグにブロックされ、リアルタイムエフェクトの出荷は一年先送りとなった。
二年目 一年後に向けてアルゴリズムチームはエフェクト実装の改善を進めていた。 具体的には消費電力の改善に取り組んでいた。（つまり OS のバグがあろうがなかろうが出荷できなかったのだね・・・。） 試行錯誤の過程で、彼らはアプリとのインテグレーションも大きくデザインを変えていた。つまり森田がハカソンで書いたコードは姿を消していた。
その仕事のことをすっかり忘れていたある日、アルゴリズム班の人がやってきて「エフェクトが動かないのでなんとかしてほしい」という。 久しぶりに見ると見慣れないコードばかり。インテグレーションに使う OS の API も SurfaceView から ImageReader へ、ずいぶん変わっている。 そしてこれが動かないのは・・・ OS のバグなのでは？ 嫌な既視感に襲われつつバグを報告するも、やはり直らないバグ。またしびれを切らして直談判。</description>
    </item>
    
  </channel>
</rss>
